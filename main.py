from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import asyncio
import httpx
from datetime import datetime
import uuid
from enum import Enum
import logging

app = FastAPI(title="OrchestraAI", description="Multi-AI Collaboration Platform")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('orchestra_ai.log')
    ]
)
logger = logging.getLogger(__name__)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class RoleType(str, Enum):
    HUMAN = "human"
    ETHER = "ether"
    PRODUCT_AI = "product_ai"
    ARCHITECT_AI = "architect_ai"
    INTERFACE_AI = "interface_ai"
    PROGRAMMER_AI = "programmer_ai"

class MessageType(str, Enum):
    USER_INPUT = "user_input"
    AI_RESPONSE = "ai_response"
    SYSTEM_INFO = "system_info"
    FILE_SAVED = "file_saved"
    ERROR = "error"

class Message(BaseModel):
    id: str
    role: RoleType
    message_type: MessageType
    content: str
    timestamp: datetime
    metadata: Optional[Dict[str, Any]] = None

class OrchestraState:
    def __init__(self):
        self.messages: List[Message] = []
        self.websocket_connections: List[WebSocket] = []
        self.selected_model: str = "gpt-oss:20b"  # é»˜è®¤æ¨¡å‹
        self.conversation_summaries: Dict[str, str] = {}  # å„é˜¶æ®µçš„å¯¹è¯æ€»ç»“

    def get_context_for_role(self, role: RoleType, max_messages: Optional[int] = None) -> str:
        """è·å–ç‰¹å®šè§’è‰²çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåªä½¿ç”¨æ€»ç»“ï¼‰"""
        # å¦‚æœæœ‰æ€»ç»“ï¼Œç›´æ¥è¿”å›æœ€æ–°çš„æ€»ç»“
        if self.conversation_summaries:
            latest_summary = list(self.conversation_summaries.values())[-1]
            logger.info(f"ä¸ºè§’è‰² {role.value} æä¾›æ€»ç»“ä¸Šä¸‹æ–‡ï¼Œæ€»ç»“é•¿åº¦: {len(latest_summary)}")
            return latest_summary
        else:
            # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè®©AIåŸºäºå½“å‰æç¤ºè¯å·¥ä½œ
            logger.info(f"ä¸ºè§’è‰² {role.value} æä¾›ç©ºä¸Šä¸‹æ–‡ï¼ˆæ— æ€»ç»“ï¼‰")
            return ""

def get_role_display_name(role: RoleType) -> str:
    """è·å–è§’è‰²æ˜¾ç¤ºåç§°"""
    role_names = {
        RoleType.HUMAN: "äººç±»ç”¨æˆ·",
        RoleType.ETHER: "ç³»ç»Ÿ",
        RoleType.PRODUCT_AI: "äº§å“AI",
        RoleType.ARCHITECT_AI: "æ¶æ„AI",
        RoleType.INTERFACE_AI: "æ¥å£AI",
        RoleType.PROGRAMMER_AI: "ç¨‹åºå‘˜AI"
    }
    return role_names.get(role, role.value)

orchestra_state = OrchestraState()

AI_PROMPTS = {
    RoleType.PRODUCT_AI: """
ä½ æ˜¯äº§å“AIï¼Œè´Ÿè´£éœ€æ±‚åˆ†æå’Œäº§å“è®¾è®¡ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š

**ç¬¬ä¸€é˜¶æ®µ - éœ€æ±‚æ”¶é›†**ï¼š
1. æ”¶åˆ°äººç±»çš„åˆå§‹éœ€æ±‚åï¼Œå‘äººç±»æå‡ºå…·ä½“çš„é—®é¢˜æ¥æ˜ç¡®éœ€æ±‚ç»†èŠ‚
2. é—®é¢˜è¦å…·ä½“ï¼Œæœ€å¥½æ˜¯é€‰æ‹©é¢˜ï¼Œé¿å…æ¨¡ç³Šé—®é¢˜
3. æ˜ç¡®éœ€æ±‚çš„å“ªäº›æ–¹é¢æ˜¯äººç±»åœ¨ä¹çš„ï¼Œå“ªäº›æ˜¯æ— æ‰€è°“çš„
4. æ¯æ¬¡å›å¤éƒ½è¦è¯„ä¼°ï¼šæ˜¯å¦å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯æ¥è®¾è®¡äº§å“

**ç¬¬äºŒé˜¶æ®µ - éœ€æ±‚ç¡®è®¤ä¸æ€»ç»“**ï¼š
å½“ä½ è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯æ—¶ï¼Œå¿…é¡»ï¼š
1. æ˜ç¡®å£°æ˜ï¼š"åŸºäºæˆ‘ä»¬çš„å¯¹è¯ï¼Œæˆ‘è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„äº§å“éœ€æ±‚ä¿¡æ¯"
2. æä¾›å®Œæ•´çš„éœ€æ±‚æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
   - æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚
   - ç”¨æˆ·è§’è‰²å’Œæƒé™
   - å…³é”®ä¸šåŠ¡æµç¨‹
   - æŠ€æœ¯è¦æ±‚å’Œçº¦æŸ
   - ä¼˜å…ˆçº§è¯´æ˜
3. è¯¢é—®ç”¨æˆ·ï¼š"è¯·ç¡®è®¤ä»¥ä¸Šéœ€æ±‚æ€»ç»“æ˜¯å¦å®Œæ•´å‡†ç¡®ï¼Ÿå¦‚æœç¡®è®¤æ— è¯¯ï¼Œæˆ‘å°†æŠŠéœ€æ±‚ç§»äº¤ç»™æ¶æ„AIè¿›è¡ŒæŠ€æœ¯è®¾è®¡ã€‚"

**é‡è¦åŸåˆ™**ï¼š
- ä¸è¦æ— é™åˆ¶åœ°é—®é—®é¢˜ï¼Œé€šå¸¸3-5è½®å¯¹è¯åº”è¯¥èƒ½æ”¶é›†åˆ°åŸºæœ¬ä¿¡æ¯
- è¦ä¸»åŠ¨åˆ¤æ–­ä½•æ—¶ä¿¡æ¯å·²ç»è¶³å¤Ÿè¿›è¡Œäº§å“è®¾è®¡
- å¦‚æœé‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜ï¼ŒåŠæ—¶ä¸ŠæŠ¥ç»™äººç±»
- ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€ä¸äººç±»æ²Ÿé€š

**å›å¤æ ¼å¼æŒ‡å¯¼**ï¼š
- å¦‚æœè¿˜éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œç»§ç»­æé—®
- å¦‚æœä¿¡æ¯è¶³å¤Ÿï¼Œä½¿ç”¨"ã€éœ€æ±‚ç¡®è®¤ã€‘"æ ‡è®°å¼€å§‹éœ€æ±‚æ€»ç»“
""",

    RoleType.ARCHITECT_AI: """
ä½ æ˜¯æ¶æ„AIï¼Œè´Ÿè´£æŠ€æœ¯æ¶æ„è®¾è®¡å’Œä»»åŠ¡åˆ†è§£ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. ä»ä»£ç å®ç°è§’åº¦å°†äº§å“éœ€æ±‚è½¬æ¢ä¸ºå…·ä½“çš„å®ç°æ­¥éª¤
2. ç¡®å®šå“ªäº›æ­¥éª¤èƒ½å¹¶è¡Œæ‰§è¡Œï¼Œå“ªäº›æœ‰ä¾èµ–å…³ç³»
3. å°†æœ‰ä¾èµ–å…³ç³»çš„æ­¥éª¤äº¤ç»™æ¥å£AIè®¾è®¡æ¥å£
4. è®¾è®¡æ–‡ä»¶ç›®å½•ç»“æ„ï¼Œç¡®å®šä»£ç æ–‡ä»¶çš„å­˜æ”¾ä½ç½®
5. å°†å¯æ‰§è¡Œçš„ä»»åŠ¡åˆ†é…ç»™ç¨‹åºå‘˜AI
6. æ”¶é›†å¹¶æ‹¼æ¥ç¨‹åºå‘˜AIçš„ä»£ç ï¼Œé€šè¿‡ä»¥å¤ªä¿å­˜æ–‡ä»¶

è¯·ç¡®ä¿æ¶æ„è®¾è®¡åˆç†ï¼Œä»»åŠ¡åˆ†è§£æ¸…æ™°ï¼Œä¾¿äºå¹¶è¡Œå¼€å‘ã€‚
""",

    RoleType.INTERFACE_AI: """
ä½ æ˜¯æ¥å£AIï¼Œè´Ÿè´£è®¾è®¡æ¨¡å—é—´çš„æ¥å£ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. ä¸ºæœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡è®¾è®¡æ¸…æ™°çš„æ¥å£è§„èŒƒ
2. å®šä¹‰æ•°æ®ç»“æ„ã€å‡½æ•°ç­¾åã€APIè§„èŒƒ
3. ç¡®ä¿æ¥å£è®¾è®¡ç¬¦åˆæœ€ä½³å®è·µï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
4. æä¾›è¯¦ç»†çš„æ¥å£æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

è¯·ç¡®ä¿æ¥å£è®¾è®¡è§„èŒƒã€ä¸€è‡´ï¼Œä¾¿äºä¸åŒæ¨¡å—çš„é›†æˆã€‚
""",

    RoleType.PROGRAMMER_AI: """
ä½ æ˜¯ç¨‹åºå‘˜AIï¼Œè´Ÿè´£å…·ä½“çš„ä»£ç å®ç°ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. æ ¹æ®æ¶æ„AIåˆ†é…çš„ä»»åŠ¡å®ç°å…·ä½“ä»£ç 
2. éµå¾ªæ¥å£AIè®¾è®¡çš„æ¥å£è§„èŒƒ
3. ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç 
4. åŒ…å«å¿…è¦çš„æ³¨é‡Šå’Œé”™è¯¯å¤„ç†
5. ç¡®ä¿ä»£ç ç¬¦åˆæœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ

è¯·ç¼–å†™æ¸…æ™°ã€é«˜æ•ˆçš„ä»£ç ï¼Œæ³¨é‡ä»£ç è´¨é‡å’Œå¯è¯»æ€§ã€‚
"""
}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    orchestra_state.websocket_connections.append(websocket)

    try:
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "messages": [msg.model_dump(mode="json") for msg in orchestra_state.messages[-50:]]
        }))

        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            await handle_human_input(message_data["content"])

    except WebSocketDisconnect:
        orchestra_state.websocket_connections.remove(websocket)

async def broadcast_message(message: Message):
    orchestra_state.messages.append(message)

    disconnected = []
    for websocket in orchestra_state.websocket_connections:
        try:
            await websocket.send_text(json.dumps({
                "type": "new_message",
                "message": message.model_dump(mode="json")
            }))
        except:
            disconnected.append(websocket)

    for ws in disconnected:
        orchestra_state.websocket_connections.remove(ws)

async def handle_human_input(content: str):
    logger.info(f"æ”¶åˆ°äººç±»è¾“å…¥: {content}")  # å®Œæ•´è®°å½•

    message = Message(
        id=str(uuid.uuid4()),
        role=RoleType.HUMAN,
        message_type=MessageType.USER_INPUT,
        content=content,
        timestamp=datetime.now()
    )

    await broadcast_message(message)

    await trigger_product_ai(content)

async def trigger_product_ai(user_input: str):
    logger.info(f"è§¦å‘äº§å“AIåˆ†æç”¨æˆ·éœ€æ±‚: {user_input}")  # å®Œæ•´è®°å½•

    # ç»Ÿè®¡äº§å“AIå’Œäººç±»çš„å¯¹è¯è½®æ•°æ¥åˆ¤æ–­æ˜¯å¦åº”è¯¥å¼€å§‹æ€»ç»“
    product_ai_messages = sum(1 for msg in orchestra_state.messages
                             if msg.role == RoleType.PRODUCT_AI and msg.message_type == MessageType.AI_RESPONSE)

    if product_ai_messages >= 2:  # 2è½®å¯¹è¯åå¼€å§‹æé†’æ€»ç»“
        additional_instruction = """

**é‡è¦æé†’**: è¿™å·²ç»æ˜¯æˆ‘ä»¬çš„ç¬¬{}è½®å¯¹è¯äº†ã€‚è¯·è¯„ä¼°æ˜¯å¦å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„éœ€æ±‚ä¿¡æ¯ã€‚å¦‚æœæ˜¯ï¼Œè¯·ä½¿ç”¨"ã€éœ€æ±‚ç¡®è®¤ã€‘"æ ‡è®°å¼€å§‹éœ€æ±‚æ€»ç»“ã€‚""".format(product_ai_messages + 1)
    else:
        additional_instruction = ""

    prompt = f"""
{AI_PROMPTS[RoleType.PRODUCT_AI]}

ç”¨æˆ·è¾“å…¥ï¼š{user_input}

è¯·æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ç»§ç»­éœ€æ±‚åˆ†æã€‚å¦‚æœè¿™æ˜¯åˆå§‹éœ€æ±‚ï¼Œè¯·æå‡º3-5ä¸ªå…·ä½“çš„æ¾„æ¸…é—®é¢˜ã€‚å¦‚æœè¿™æ˜¯å¯¹ä¹‹å‰é—®é¢˜çš„å›ç­”ï¼Œè¯·åŸºäºå·²æœ‰ä¿¡æ¯ç»§ç»­æ·±å…¥äº†è§£æˆ–è€ƒè™‘æ˜¯å¦å¯ä»¥å¼€å§‹éœ€æ±‚æ€»ç»“ã€‚{additional_instruction}
"""

    response = await call_ollama_api(prompt, RoleType.PRODUCT_AI)
    if response:
        logger.info(f"äº§å“AIå“åº”ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response)}å­—ç¬¦")
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.PRODUCT_AI,
            message_type=MessageType.AI_RESPONSE,
            content=response,
            timestamp=datetime.now()
        )
        await broadcast_message(message)
    else:
        logger.error("äº§å“AIå“åº”ç”Ÿæˆå¤±è´¥")

async def trigger_architect_ai(requirement: str):
    logger.info(f"è§¦å‘æ¶æ„AIè®¾è®¡æŠ€æœ¯æ–¹æ¡ˆ: {requirement}")  # å®Œæ•´è®°å½•

    prompt = f"""
{AI_PROMPTS[RoleType.ARCHITECT_AI]}

äº§å“éœ€æ±‚ï¼š{requirement}

è¯·åˆ†æè¿™ä¸ªéœ€æ±‚å¹¶è¿›è¡ŒæŠ€æœ¯æ¶æ„è®¾è®¡ï¼š
1. åˆ†è§£ä¸ºå…·ä½“çš„å®ç°æ­¥éª¤
2. è¯†åˆ«æ­¥éª¤é—´çš„ä¾èµ–å…³ç³»
3. è®¾è®¡æ–‡ä»¶ç›®å½•ç»“æ„
4. åˆ¶å®šå¼€å‘è®¡åˆ’
"""

    response = await call_ollama_api(prompt, RoleType.ARCHITECT_AI)
    if response:
        logger.info(f"æ¶æ„AIæ–¹æ¡ˆè®¾è®¡æˆåŠŸï¼Œé•¿åº¦: {len(response)}å­—ç¬¦")
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ARCHITECT_AI,
            message_type=MessageType.AI_RESPONSE,
            content=response,
            timestamp=datetime.now()
        )
        await broadcast_message(message)
    else:
        logger.error("æ¶æ„AIæ–¹æ¡ˆè®¾è®¡å¤±è´¥")

async def call_ollama_api(prompt: str, role: RoleType, include_context: bool = True) -> Optional[str]:
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] å¼€å§‹Ollama APIè°ƒç”¨ - è§’è‰²: {role.value}, æ¨¡å‹: {orchestra_state.selected_model}")

    try:
        # å¦‚æœæ˜¯æœ‰è§’è‰²çš„AIï¼ˆä¸æ˜¯ETHERæ€»ç»“AIï¼‰ï¼Œå…ˆç”Ÿæˆ/æ›´æ–°æ€»ç»“
        if role != RoleType.ETHER and len(orchestra_state.messages) > 0:
            await ensure_summary_updated()

        ether_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content=f"æ­£åœ¨è°ƒç”¨Ollama APIä¸º{role.value}ç”Ÿæˆå“åº”...",
            timestamp=datetime.now()
        )
        await broadcast_message(ether_message)

        # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ï¼‰
        full_prompt = prompt
        if include_context and len(orchestra_state.messages) > 0:
            context = orchestra_state.get_context_for_role(role)
            if context:
                full_prompt = f"""ä»¥ä¸‹æ˜¯ç›¸å…³çš„å¯¹è¯å†å²ï¼š

{context}

---

åŸºäºä»¥ä¸Šå¯¹è¯å†å²ï¼Œè¯·å›åº”ä»¥ä¸‹è¯·æ±‚ï¼š

{prompt}

è¯·ç¡®ä¿ä½ çš„å›åº”è€ƒè™‘åˆ°ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œä¿æŒè¿è´¯æ€§ã€‚"""

                context_stats = {
                    "total_messages": len(orchestra_state.messages),
                    "context_length": len(context),
                    "context_lines": len(context.split('\n')) if context else 0
                }
                logger.info(f"[{request_id}] ä¸Šä¸‹æ–‡ç»Ÿè®¡: {json.dumps(context_stats, ensure_ascii=False)}")

        # è®°å½•Ollamaè¾“å…¥
        logger.info(f"[{request_id}] ===== OLLAMAè¾“å…¥ =============================")
        logger.info(f"[{request_id}] æ¨¡å‹: {orchestra_state.selected_model}")
        logger.info(f"[{request_id}] è¾“å…¥Prompt: {full_prompt}")
        logger.info(f"[{request_id}] ================================================")

        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": orchestra_state.selected_model,
                    "prompt": full_prompt,
                    "stream": False
                },
                timeout=1000.0
            )

            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"[{request_id}] APIè°ƒç”¨è€—æ—¶: {duration:.2f}ç§’")

            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "")

                # è®°å½•å“åº”è¯¦æƒ…ï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼‰
                logger.info(f"[{request_id}] ===== OLLAMAè¾“å‡º =============================")
                logger.info(f"[{request_id}] å“åº”é•¿åº¦: {len(response_text)}å­—ç¬¦")
                logger.info(f"[{request_id}] è¾“å‡ºå†…å®¹: {response_text}")
                logger.info(f"[{request_id}] ================================================")

                # è®°å½•é¢å¤–çš„å“åº”ä¿¡æ¯
                if 'eval_count' in result:
                    logger.info(f"[{request_id}] Tokenç»Ÿè®¡ - è¾“å‡º: {result.get('eval_count', 0)}, è¾“å…¥: {result.get('prompt_eval_count', 0)}")
                if 'total_duration' in result:
                    total_duration_sec = result['total_duration'] / 1e9
                    logger.info(f"[{request_id}] æ€»å¤„ç†æ—¶é—´: {total_duration_sec:.2f}ç§’")

                return response_text
            else:
                error_msg = f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}"
                logger.error(f"[{request_id}] {error_msg} - å“åº”å†…å®¹: {response.text}")

                error_message = Message(
                    id=str(uuid.uuid4()),
                    role=RoleType.ETHER,
                    message_type=MessageType.ERROR,
                    content=error_msg,
                    timestamp=datetime.now()
                )
                await broadcast_message(error_message)
                return None

    except Exception as e:
        error_msg = f"è°ƒç”¨Ollama APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(f"[{request_id}] {error_msg}", exc_info=True)

        error_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.ERROR,
            content=error_msg,
            timestamp=datetime.now()
        )
        await broadcast_message(error_message)
        return None

async def ensure_summary_updated():
    """ç¡®ä¿æ€»ç»“æ˜¯æœ€æ–°çš„ï¼Œå¦‚æœéœ€è¦åˆ™ç”Ÿæˆæ–°æ€»ç»“"""
    messages_since_last_summary = get_messages_since_last_summary()

    # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œæˆ–è‡ªä¸Šæ¬¡æ€»ç»“åæœ‰æ–°æ¶ˆæ¯ï¼Œåˆ™ç”Ÿæˆæ–°æ€»ç»“
    if not orchestra_state.conversation_summaries or len(messages_since_last_summary) > 0:
        logger.info("æ£€æµ‹åˆ°éœ€è¦æ›´æ–°æ€»ç»“ï¼Œå¼€å§‹ç”Ÿæˆ...")
        await generate_conversation_summary()

def get_messages_since_last_summary() -> List[Message]:
    """è·å–è‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯"""
    if not orchestra_state.conversation_summaries:
        return orchestra_state.messages

    # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“çš„æ—¶é—´æ ‡è®°
    last_summary_time = None
    for msg in reversed(orchestra_state.messages):
        if (msg.role == RoleType.ETHER and
            msg.message_type == MessageType.SYSTEM_INFO and
            "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
            last_summary_time = msg.timestamp
            break

    if last_summary_time:
        return [msg for msg in orchestra_state.messages if msg.timestamp > last_summary_time]
    else:
        return orchestra_state.messages

async def generate_conversation_summary():
    """ç”Ÿæˆå¯¹è¯æ€»ç»“"""
    try:
        if len(orchestra_state.messages) < 4:  # æ¶ˆæ¯å¤ªå°‘ä¸éœ€è¦æ€»ç»“
            return

        logger.info("å¼€å§‹ç”Ÿæˆå¯¹è¯æ€»ç»“")

        # è·å–å½“å‰å¯¹è¯æ®µè½çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆè‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯ï¼‰
        if orchestra_state.conversation_summaries:
            # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯
            last_summary_time = None
            for msg in reversed(orchestra_state.messages):
                if (msg.role == RoleType.ETHER and
                    msg.message_type == MessageType.SYSTEM_INFO and
                    "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
                    last_summary_time = msg.timestamp
                    break

            if last_summary_time:
                current_conversation = [msg for msg in orchestra_state.messages if msg.timestamp > last_summary_time]
            else:
                current_conversation = orchestra_state.messages[-20:]  # å¦‚æœæ‰¾ä¸åˆ°æ ‡è®°ï¼Œä½¿ç”¨æœ€è¿‘20æ¡
        else:
            # ç¬¬ä¸€æ¬¡æ€»ç»“ï¼Œä½¿ç”¨æ‰€æœ‰æ¶ˆæ¯
            current_conversation = orchestra_state.messages

        # å¦‚æœæ¶ˆæ¯å¤ªå°‘ï¼Œä¸ç”Ÿæˆæ€»ç»“
        if len(current_conversation) < 3:
            logger.info(f"å½“å‰å¯¹è¯æ®µè½æ¶ˆæ¯å¤ªå°‘({len(current_conversation)}æ¡)ï¼Œè·³è¿‡æ€»ç»“")
            return

        recent_messages = current_conversation

        # æ„å»ºæ€»ç»“æç¤ºè¯ï¼Œè¿‡æ»¤æ‰ä»¥å¤ª(ç³»ç»Ÿ)æ¶ˆæ¯
        messages_text = []
        for msg in recent_messages:
            # è·³è¿‡ä»¥å¤ª(ç³»ç»Ÿ)çš„æ¶ˆæ¯ï¼Œåªä¿ç•™å®é™…å¯¹è¯
            if msg.role == RoleType.ETHER:
                continue
            role_name = get_role_display_name(msg.role)
            timestamp = msg.timestamp.strftime("%H:%M:%S")
            messages_text.append(f"[{timestamp}] {role_name}: {msg.content}")

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„æ€»ç»“ï¼Œå¦‚æœæœ‰ï¼Œåˆ™ç”Ÿæˆå¢é‡æ€»ç»“
        previous_summary = ""
        if orchestra_state.conversation_summaries:
            latest_summary = list(orchestra_state.conversation_summaries.values())[-1]
            previous_summary = f"""
ä¹‹å‰çš„å¯¹è¯æ€»ç»“ï¼š
{latest_summary}

---
"""

        summary_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯æ€»ç»“AIï¼Œéœ€è¦ä¸ºå¤šAIåä½œç³»ç»Ÿç”Ÿæˆç®€æ´æœ‰æ•ˆçš„å¯¹è¯æ€»ç»“ã€‚è¿™ä¸ªæ€»ç»“å°†ä½œä¸ºAIå¯¹è¯æ—¶çš„ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„èŠå¤©å†å²ã€‚

{previous_summary}
æœ¬æ¬¡æ–°å¢å¯¹è¯å†…å®¹ï¼š
{chr(10).join(messages_text)}

æ€»ç»“ç›®æ ‡ï¼š
ç”Ÿæˆä¸€ä¸ªç®€æ´ä½†ä¿¡æ¯å®Œæ•´çš„æ€»ç»“ï¼Œç”¨äºæ›¿ä»£å®Œæ•´çš„èŠå¤©å†å²ï¼Œè®©AIèƒ½å¤Ÿç†è§£ï¼š
1. **å½“å‰é¡¹ç›®çŠ¶æ€**ï¼šéœ€æ±‚ç¡®è®¤æƒ…å†µã€è®¾è®¡è¿›å±•ã€å¼€å‘çŠ¶æ€
2. **å…³é”®æŠ€æœ¯å†³ç­–**ï¼šæ¶æ„é€‰æ‹©ã€æŠ€æœ¯æ ˆã€è®¾è®¡åŸåˆ™
3. **é‡è¦çº¦æŸæ¡ä»¶**ï¼šç”¨æˆ·è¦æ±‚ã€æŠ€æœ¯é™åˆ¶ã€ä¸šåŠ¡è§„åˆ™
4. **å¾…è§£å†³é—®é¢˜**ï¼šå½“å‰é˜»å¡ç‚¹ã€éœ€è¦æ¾„æ¸…çš„é—®é¢˜
5. **ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼šæ˜ç¡®çš„åç»­ä»»åŠ¡å’Œè´£ä»»åˆ†å·¥

æ€»ç»“è¦æ±‚ï¼š
- ä¿æŒå®¢è§‚äº‹å®ï¼Œé¿å…å†—ä½™æè¿°
- çªå‡ºæ ¸å¿ƒä¿¡æ¯ï¼Œå¿½ç•¥å®¢å¥—è¯
- ä½¿ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼
- ç¡®ä¿AIèƒ½åŸºäºæ­¤æ€»ç»“ç»§ç»­åä½œ
- æ€»ç»“é•¿åº¦æ§åˆ¶åœ¨500å­—ä»¥å†…

è¯·ç”Ÿæˆç»“æ„åŒ–æ€»ç»“ï¼š
"""

        # è°ƒç”¨AIç”Ÿæˆæ€»ç»“ï¼ˆæ€»ç»“AIéœ€è¦ç‰¹æ®Šçš„ä¸Šä¸‹æ–‡å¤„ç†ï¼‰
        summary = await call_ollama_api_for_summary(summary_prompt)

        if summary:
            # ä¿å­˜æ€»ç»“
            summary_key = f"summary_{len(orchestra_state.messages)}"
            orchestra_state.conversation_summaries[summary_key] = summary

            logger.info(f"å¯¹è¯æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œä¿å­˜ä¸º {summary_key}")
            logger.info(f"æ€»ç»“å†…å®¹: {summary}")

            # å°†æ€»ç»“å†…å®¹ä½œä¸ºETHERæ¶ˆæ¯å±•ç¤ºåœ¨ç•Œé¢ä¸Š
            summary_display_message = Message(
                id=str(uuid.uuid4()),
                role=RoleType.ETHER,
                message_type=MessageType.SYSTEM_INFO,
                content=f"ğŸ“‹ **å¯¹è¯æ€»ç»“**\n\n{summary}",
                timestamp=datetime.now()
            )
            # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½è°ƒç”¨broadcast_messageï¼Œä¼šå¯¼è‡´é€’å½’
            orchestra_state.messages.append(summary_display_message)

            # ç›´æ¥å‘é€ç»™å®¢æˆ·ç«¯å±•ç¤ºæ€»ç»“å†…å®¹
            for websocket in orchestra_state.websocket_connections:
                try:
                    await websocket.send_text(json.dumps({
                        "type": "new_message",
                        "message": summary_display_message.model_dump(mode="json")
                    }))
                except:
                    pass

        else:
            logger.error("å¯¹è¯æ€»ç»“ç”Ÿæˆå¤±è´¥")

    except Exception as e:
        logger.error(f"ç”Ÿæˆå¯¹è¯æ€»ç»“æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)

async def call_ollama_api_for_summary(prompt: str) -> Optional[str]:
    """ä¸“é—¨ç”¨äºè°ƒç”¨æ€»ç»“AIçš„å‡½æ•°ï¼Œä¸è§¦å‘æ€»ç»“æ›´æ–°"""
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] å¼€å§‹è°ƒç”¨æ€»ç»“AI - æ¨¡å‹: {orchestra_state.selected_model}")

    try:
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": orchestra_state.selected_model,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=1000.0
            )

            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"[{request_id}] æ€»ç»“APIè°ƒç”¨è€—æ—¶: {duration:.2f}ç§’")

            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "")

                logger.info(f"[{request_id}] æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response_text)}å­—ç¬¦")
                return response_text
            else:
                error_msg = f"æ€»ç»“AIè°ƒç”¨å¤±è´¥: {response.status_code}"
                logger.error(f"[{request_id}] {error_msg}")
                return None

    except Exception as e:
        error_msg = f"è°ƒç”¨æ€»ç»“AIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(f"[{request_id}] {error_msg}", exc_info=True)
        return None

@app.get("/api/models")
async def get_available_models():
    logger.info("æ­£åœ¨è·å–å¯ç”¨çš„Ollamaæ¨¡å‹åˆ—è¡¨")
    try:
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:11434/api/tags", timeout=1000.0)
            duration = (datetime.now() - start_time).total_seconds()

            if response.status_code == 200:
                data = response.json()
                models = [model["name"] for model in data.get("models", [])]
                logger.info(f"æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨ (è€—æ—¶ {duration:.2f}ç§’): {models}")
                logger.info(f"å½“å‰é€‰ä¸­æ¨¡å‹: {orchestra_state.selected_model}")
                return {"models": models, "selected": orchestra_state.selected_model}
            else:
                logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ - HTTP {response.status_code}: {response.text}")
                return {"models": [""], "selected": orchestra_state.selected_model, "error": "Failed to fetch models"}
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return {"models": [""], "selected": orchestra_state.selected_model, "error": str(e)}

class ModelSelection(BaseModel):
    model_name: str

@app.post("/api/select_model")
async def select_model(model_data: ModelSelection):
    old_model = orchestra_state.selected_model
    new_model = model_data.model_name

    logger.info(f"æ¨¡å‹åˆ‡æ¢è¯·æ±‚: {old_model} -> {new_model}")

    orchestra_state.selected_model = new_model

    logger.info(f"æ¨¡å‹å·²æˆåŠŸåˆ‡æ¢ä¸º: {new_model}")

    return {"status": "success", "selected_model": new_model}

@app.get("/")
async def serve_frontend():
    return FileResponse("static/index.html")

app.mount("/static", StaticFiles(directory="static"), name="static")

if __name__ == "__main__":
    import uvicorn
    logger.info("å¯åŠ¨OrchestraAIå¤šAIåä½œå¹³å°")
    logger.info(f"é»˜è®¤é€‰æ‹©æ¨¡å‹: {orchestra_state.selected_model}")
    logger.info("æœåŠ¡å™¨å°†åœ¨ http://0.0.0.0:8000 å¯åŠ¨")
    uvicorn.run(app, host="0.0.0.0", port=8000)