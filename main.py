from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from contextlib import asynccontextmanager
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import asyncio
import httpx
from datetime import datetime
import uuid
from enum import Enum
import logging
import socket
import random

@asynccontextmanager
async def lifespan(app: FastAPI):
    await orchestra_state.initialize_model()
    yield

app = FastAPI(title="OrchestraAI", description="Multi-AI Collaboration Platform", lifespan=lifespan)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('orchestra_ai.log')
    ]
)
logger = logging.getLogger(__name__)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class RoleType(str, Enum):
    HUMAN = "human"
    ETHER = "ether"
    PRODUCT_AI = "product_ai"
    ARCHITECT_AI = "architect_ai"
    INTERFACE_AI = "interface_ai"
    PROGRAMMER_AI = "programmer_ai"

class MessageType(str, Enum):
    USER_INPUT = "user_input"
    AI_RESPONSE = "ai_response"
    SYSTEM_INFO = "system_info"
    FILE_SAVED = "file_saved"
    ERROR = "error"

class Message(BaseModel):
    id: str
    role: RoleType
    message_type: MessageType
    content: str
    timestamp: datetime
    metadata: Optional[Dict[str, Any]] = None

class OrchestraState:
    def __init__(self):
        self.messages: List[Message] = []
        self.websocket_connections: List[WebSocket] = []
        self.selected_model: str = ""
        self.conversation_summaries: Dict[str, str] = {}  # å„é˜¶æ®µçš„å¯¹è¯æ€»ç»“
        
    async def initialize_model(self):
        """åˆå§‹åŒ–é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹"""
        if not self.selected_model:
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get("http://localhost:11434/api/tags", timeout=10.0)
                    if response.status_code == 200:
                        data = response.json()
                        models = [model["name"] for model in data.get("models", [])]
                        if models:
                            self.selected_model = models[0]
                            logger.info(f"è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹: {self.selected_model}")
                        else:
                            logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
                    else:
                        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code}")
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    def get_context_for_role(self, role: RoleType, max_messages: Optional[int] = None) -> str:
        """è·å–ç‰¹å®šè§’è‰²çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåªä½¿ç”¨æ€»ç»“ï¼‰"""
        # å¦‚æœæœ‰æ€»ç»“ï¼Œç›´æ¥è¿”å›æœ€æ–°çš„æ€»ç»“
        if self.conversation_summaries:
            latest_summary = list(self.conversation_summaries.values())[-1]
            logger.info(f"ä¸ºè§’è‰² {role.value} æä¾›æ€»ç»“ä¸Šä¸‹æ–‡ï¼Œæ€»ç»“é•¿åº¦: {len(latest_summary)}")
            return latest_summary
        else:
            # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè®©AIåŸºäºå½“å‰æç¤ºè¯å·¥ä½œ
            logger.info(f"ä¸ºè§’è‰² {role.value} æä¾›ç©ºä¸Šä¸‹æ–‡ï¼ˆæ— æ€»ç»“ï¼‰")
            return ""

def get_role_display_name(role: RoleType) -> str:
    """è·å–è§’è‰²æ˜¾ç¤ºåç§°"""
    role_names = {
        RoleType.HUMAN: "äººç±»ç”¨æˆ·",
        RoleType.ETHER: "ç³»ç»Ÿ",
        RoleType.PRODUCT_AI: "äº§å“AI",
        RoleType.ARCHITECT_AI: "æ¶æ„AI",
        RoleType.INTERFACE_AI: "æ¥å£AI",
        RoleType.PROGRAMMER_AI: "ç¨‹åºå‘˜AI"
    }
    return role_names.get(role, role.value)

orchestra_state = OrchestraState()

class TalkAbout(str, Enum):
    ASK_WHY = 'ask_why'
    EXPLAIN_WHY = 'explain_why'
    ABOUT_HOW = 'about_how'
    ABOUT_WHAT = 'about_what'
    ABOUT_DISCRIMINATION = 'about_discrimination'
    ABOUT_REFLECT = 'about_reflect'
    JUDGE = 'judge'

AI_PROMPTS = {
    RoleType.PRODUCT_AI: {
        TalkAbout.ASK_WHY: '''
# æ¨æµ‹ç”¨æˆ·ä¸ºä»€ä¹ˆæœ‰è¿™ä¸ªéœ€æ±‚
ç”¨æˆ·æå‡ºäº†ä¸€ä¸ªéœ€æ±‚ï¼Œæˆ‘ä»¬çš„ç¬¬ä¸€æ­¥å°±æ˜¯è¦åˆ†æè¿™ä¸ªéœ€æ±‚è§£å†³ç”¨æˆ·çš„ä»€ä¹ˆç—›ç‚¹ã€‚ä¸è¦ç›´æ¥å‘ç”¨æˆ·æé—®ä¸ºä»€ä¹ˆæœ‰è¿™ä¸ªéœ€æ±‚ï¼Œè€Œæ˜¯è¦ä¸åœçŒœæµ‹ç—›ç‚¹ï¼Œç›´åˆ°ç”¨æˆ·è®¤åŒã€‚
''',
        TalkAbout.EXPLAIN_WHY: '''

''',
        TalkAbout.ABOUT_HOW: '''

''',
        TalkAbout.ABOUT_WHAT: '''
''',
        TalkAbout.ABOUT_REFLECT: '''
''',
        TalkAbout.ABOUT_DISCRIMINATION: '''
# åˆ¤æ–­è¯è¯­ç±»å‹
ä½ ä¼šæ”¶åˆ°ä¸€æ¡äººç±»æ–°è¾“å…¥çš„æ¶ˆæ¯ï¼Œè¯·åˆ¤æ–­è¿™æ¡æ¶ˆæ¯å±äºä»¥ä¸‹å“ªç§ç±»å‹çš„æ¶ˆæ¯ï¼š
- 1. è¡¨è¾¾æ„¿æœ›ï¼Œæˆ–è€…è¡¨è¾¾ä¸€ä¸ªæƒ³æ³•
- 2. è¡¨è¾¾å¯¹åŸå› çš„ç–‘é—®
- 3. è¡¨è¾¾å¯¹å¦‚ä½•å®ç°çš„ç–‘é—®
- 4. è¡¨è¾¾å¯¹æ¦‚å¿µçš„ç–‘é—®
- 5. è¡¨è¾¾è‚¯å®šæˆ–è€…å¦å®š
- 6. æå‡ºä¸€ç§ä¸ç¡®å®šçš„å»ºè®®
- 7. ç”¨æˆ·å¸Œæœ›æœ‰æ›´å¤šåŒç±»çš„ä¿¡æ¯

äººç±»æ–°è¾“å…¥çš„æ¶ˆæ¯å¦‚ä¸‹ï¼Œè¯·åšåˆ¤æ–­ï¼Œåªè¿”å›é€‰é¡¹æ•°å­—ï¼Œä¸è¦è¿”å›å…¶ä»–ä»»ä½•å†…å®¹
''',
        'discrimination_map': {
            '1': TalkAbout.ASK_WHY,
            '2': TalkAbout.EXPLAIN_WHY,
            '3': TalkAbout.ABOUT_HOW,
            '4': TalkAbout.ABOUT_WHAT,
            '5': TalkAbout.ABOUT_REFLECT,
            '6': TalkAbout.JUDGE,
        }
    },
    # ä½ æ˜¯äº§å“AIï¼Œè´Ÿè´£éœ€æ±‚åˆ†æå’Œäº§å“è®¾è®¡ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
    #
    # **ç¬¬ä¸€é˜¶æ®µ - éœ€æ±‚æ”¶é›†**ï¼š
    # 1. æ”¶åˆ°äººç±»çš„åˆå§‹éœ€æ±‚åï¼Œå‘äººç±»æå‡ºå…·ä½“çš„é—®é¢˜æ¥æ˜ç¡®éœ€æ±‚ç»†èŠ‚
    # 2. é—®é¢˜è¦å…·ä½“ï¼Œæœ€å¥½æ˜¯é€‰æ‹©é¢˜ï¼Œé¿å…æ¨¡ç³Šé—®é¢˜
    # 3. æ˜ç¡®éœ€æ±‚çš„å“ªäº›æ–¹é¢æ˜¯äººç±»åœ¨ä¹çš„ï¼Œå“ªäº›æ˜¯æ— æ‰€è°“çš„
    # 4. æ¯æ¬¡å›å¤éƒ½è¦è¯„ä¼°ï¼šæ˜¯å¦å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯æ¥è®¾è®¡äº§å“
    #
    # **ç¬¬äºŒé˜¶æ®µ - éœ€æ±‚ç¡®è®¤ä¸æ€»ç»“**ï¼š
    # å½“ä½ è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯æ—¶ï¼Œå¿…é¡»ï¼š
    # 1. æ˜ç¡®å£°æ˜ï¼š"åŸºäºæˆ‘ä»¬çš„å¯¹è¯ï¼Œæˆ‘è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„äº§å“éœ€æ±‚ä¿¡æ¯"
    # 2. æä¾›å®Œæ•´çš„éœ€æ±‚æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
    #    - æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚
    #    - ç”¨æˆ·è§’è‰²å’Œæƒé™
    #    - å…³é”®ä¸šåŠ¡æµç¨‹
    #    - æŠ€æœ¯è¦æ±‚å’Œçº¦æŸ
    #    - ä¼˜å…ˆçº§è¯´æ˜
    # 3. è¯¢é—®ç”¨æˆ·ï¼š"è¯·ç¡®è®¤ä»¥ä¸Šéœ€æ±‚æ€»ç»“æ˜¯å¦å®Œæ•´å‡†ç¡®ï¼Ÿå¦‚æœç¡®è®¤æ— è¯¯ï¼Œæˆ‘å°†æŠŠéœ€æ±‚ç§»äº¤ç»™æ¶æ„AIè¿›è¡ŒæŠ€æœ¯è®¾è®¡ã€‚"
    #
    # **é‡è¦åŸåˆ™**ï¼š
    # - ä¸è¦æ— é™åˆ¶åœ°é—®é—®é¢˜ï¼Œé€šå¸¸3-5è½®å¯¹è¯åº”è¯¥èƒ½æ”¶é›†åˆ°åŸºæœ¬ä¿¡æ¯
    # - è¦ä¸»åŠ¨åˆ¤æ–­ä½•æ—¶ä¿¡æ¯å·²ç»è¶³å¤Ÿè¿›è¡Œäº§å“è®¾è®¡
    # - å¦‚æœé‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜ï¼ŒåŠæ—¶ä¸ŠæŠ¥ç»™äººç±»
    # - ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€ä¸äººç±»æ²Ÿé€š
    #
    # **å›å¤æ ¼å¼æŒ‡å¯¼**ï¼š
    # - å¦‚æœè¿˜éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œç»§ç»­æé—®
    # - å¦‚æœä¿¡æ¯è¶³å¤Ÿï¼Œä½¿ç”¨"ã€éœ€æ±‚ç¡®è®¤ã€‘"æ ‡è®°å¼€å§‹éœ€æ±‚æ€»ç»“

    RoleType.ARCHITECT_AI: """
ä½ æ˜¯æ¶æ„AIï¼Œè´Ÿè´£æŠ€æœ¯æ¶æ„è®¾è®¡å’Œä»»åŠ¡åˆ†è§£ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. ä»ä»£ç å®ç°è§’åº¦å°†äº§å“éœ€æ±‚è½¬æ¢ä¸ºå…·ä½“çš„å®ç°æ­¥éª¤
2. ç¡®å®šå“ªäº›æ­¥éª¤èƒ½å¹¶è¡Œæ‰§è¡Œï¼Œå“ªäº›æœ‰ä¾èµ–å…³ç³»
3. å°†æœ‰ä¾èµ–å…³ç³»çš„æ­¥éª¤äº¤ç»™æ¥å£AIè®¾è®¡æ¥å£
4. è®¾è®¡æ–‡ä»¶ç›®å½•ç»“æ„ï¼Œç¡®å®šä»£ç æ–‡ä»¶çš„å­˜æ”¾ä½ç½®
5. å°†å¯æ‰§è¡Œçš„ä»»åŠ¡åˆ†é…ç»™ç¨‹åºå‘˜AI
6. æ”¶é›†å¹¶æ‹¼æ¥ç¨‹åºå‘˜AIçš„ä»£ç ï¼Œé€šè¿‡ä»¥å¤ªä¿å­˜æ–‡ä»¶

è¯·ç¡®ä¿æ¶æ„è®¾è®¡åˆç†ï¼Œä»»åŠ¡åˆ†è§£æ¸…æ™°ï¼Œä¾¿äºå¹¶è¡Œå¼€å‘ã€‚
""",

    RoleType.INTERFACE_AI: """
ä½ æ˜¯æ¥å£AIï¼Œè´Ÿè´£è®¾è®¡æ¨¡å—é—´çš„æ¥å£ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. ä¸ºæœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡è®¾è®¡æ¸…æ™°çš„æ¥å£è§„èŒƒ
2. å®šä¹‰æ•°æ®ç»“æ„ã€å‡½æ•°ç­¾åã€APIè§„èŒƒ
3. ç¡®ä¿æ¥å£è®¾è®¡ç¬¦åˆæœ€ä½³å®è·µï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
4. æä¾›è¯¦ç»†çš„æ¥å£æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

è¯·ç¡®ä¿æ¥å£è®¾è®¡è§„èŒƒã€ä¸€è‡´ï¼Œä¾¿äºä¸åŒæ¨¡å—çš„é›†æˆã€‚
""",

    RoleType.PROGRAMMER_AI: """
ä½ æ˜¯ç¨‹åºå‘˜AIï¼Œè´Ÿè´£å…·ä½“çš„ä»£ç å®ç°ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. æ ¹æ®æ¶æ„AIåˆ†é…çš„ä»»åŠ¡å®ç°å…·ä½“ä»£ç 
2. éµå¾ªæ¥å£AIè®¾è®¡çš„æ¥å£è§„èŒƒ
3. ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç 
4. åŒ…å«å¿…è¦çš„æ³¨é‡Šå’Œé”™è¯¯å¤„ç†
5. ç¡®ä¿ä»£ç ç¬¦åˆæœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ

è¯·ç¼–å†™æ¸…æ™°ã€é«˜æ•ˆçš„ä»£ç ï¼Œæ³¨é‡ä»£ç è´¨é‡å’Œå¯è¯»æ€§ã€‚
"""
}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    orchestra_state.websocket_connections.append(websocket)

    try:
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "messages": [msg.model_dump(mode="json") for msg in orchestra_state.messages[-50:]]
        }))

        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            await handle_human_input(message_data["content"])

    except WebSocketDisconnect:
        orchestra_state.websocket_connections.remove(websocket)

async def broadcast_message(message: Message):
    orchestra_state.messages.append(message)

    disconnected = []
    for websocket in orchestra_state.websocket_connections:
        try:
            await websocket.send_text(json.dumps({
                "type": "new_message",
                "message": message.model_dump(mode="json")
            }))
        except:
            disconnected.append(websocket)

    for ws in disconnected:
        orchestra_state.websocket_connections.remove(ws)

async def handle_human_input(content: str):
    logger.info(f"æ”¶åˆ°äººç±»è¾“å…¥: {content}")  # å®Œæ•´è®°å½•

    message = Message(
        id=str(uuid.uuid4()),
        role=RoleType.HUMAN,
        message_type=MessageType.USER_INPUT,
        content=content,
        timestamp=datetime.now()
    )

    await broadcast_message(message)

    discrimination = await trigger_discrimination_ai(content, RoleType.PRODUCT_AI)

    message = Message(
        id=str(uuid.uuid4()),
        role=RoleType.ETHER,
        message_type=MessageType.AI_RESPONSE,
        content=discrimination + ' ' + AI_PROMPTS[RoleType.PRODUCT_AI]['discrimination_map'][discrimination],
        timestamp=datetime.now()
    )

    await broadcast_message(message)

    await trigger_product_ai(content, AI_PROMPTS[RoleType.PRODUCT_AI]['discrimination_map'][discrimination])

async def trigger_discrimination_ai(user_input: str, role: RoleType):
    prompt = f"""{AI_PROMPTS[role][TalkAbout.ABOUT_DISCRIMINATION]}\n{user_input}"""
    response = await call_ollama_api(prompt, RoleType.PRODUCT_AI)
    return response


async def trigger_product_ai(user_input: str, about: TalkAbout):
    logger.info(f"è§¦å‘äº§å“AIåˆ†æç”¨æˆ·éœ€æ±‚: {user_input}")  # å®Œæ•´è®°å½•

    prompt = f"""{AI_PROMPTS[RoleType.PRODUCT_AI][about]}\n
# ç”¨æˆ·è¾“å…¥  \n{user_input}
"""

    response = await call_ollama_api(prompt, RoleType.PRODUCT_AI)
    if response:
        logger.info(f"äº§å“AIå“åº”ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response)}å­—ç¬¦")
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.PRODUCT_AI,
            message_type=MessageType.AI_RESPONSE,
            content=response,
            timestamp=datetime.now()
        )
        await broadcast_message(message)
    else:
        logger.error("äº§å“AIå“åº”ç”Ÿæˆå¤±è´¥")

async def trigger_architect_ai(requirement: str):
    logger.info(f"è§¦å‘æ¶æ„AIè®¾è®¡æŠ€æœ¯æ–¹æ¡ˆ: {requirement}")  # å®Œæ•´è®°å½•

    prompt = f"""
{AI_PROMPTS[RoleType.ARCHITECT_AI]}

äº§å“éœ€æ±‚ï¼š{requirement}

è¯·åˆ†æè¿™ä¸ªéœ€æ±‚å¹¶è¿›è¡ŒæŠ€æœ¯æ¶æ„è®¾è®¡ï¼š
1. åˆ†è§£ä¸ºå…·ä½“çš„å®ç°æ­¥éª¤
2. è¯†åˆ«æ­¥éª¤é—´çš„ä¾èµ–å…³ç³»
3. è®¾è®¡æ–‡ä»¶ç›®å½•ç»“æ„
4. åˆ¶å®šå¼€å‘è®¡åˆ’
"""

    response = await call_ollama_api(prompt, RoleType.ARCHITECT_AI)
    if response:
        logger.info(f"æ¶æ„AIæ–¹æ¡ˆè®¾è®¡æˆåŠŸï¼Œé•¿åº¦: {len(response)}å­—ç¬¦")
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ARCHITECT_AI,
            message_type=MessageType.AI_RESPONSE,
            content=response,
            timestamp=datetime.now()
        )
        await broadcast_message(message)
    else:
        logger.error("æ¶æ„AIæ–¹æ¡ˆè®¾è®¡å¤±è´¥")

def get_chat_messages_since_last_summary() -> List[Dict[str, str]]:
    """è·å–è‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œæ ¼å¼åŒ–ä¸ºchatæ ¼å¼"""
    messages_since_summary = get_messages_since_last_summary()
    
    chat_messages = []
    for msg in messages_since_summary:
        # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯(ETHER)
        if msg.role == RoleType.ETHER:
            continue
            
        # å°†è§’è‰²æ˜ å°„ä¸ºchatæ ¼å¼
        if msg.role == RoleType.HUMAN:
            chat_role = "user"
        else:
            chat_role = "assistant"
            
        chat_messages.append({
            "role": chat_role,
            "content": f"[{get_role_display_name(msg.role)}] {msg.content}"
        })
    
    return chat_messages

async def call_ollama_api(prompt: str, role: RoleType) -> Optional[str]:
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] å¼€å§‹Ollama APIè°ƒç”¨ - è§’è‰²: {role.value}, æ¨¡å‹: {orchestra_state.selected_model}")

    try:
        ether_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content=prompt,
            timestamp=datetime.now()
        )
        await broadcast_message(ether_message)

        # è·å–å¯¹è¯å†å²
        chat_messages = get_chat_messages_since_last_summary()
        
        # æ„å»ºchatæ ¼å¼çš„æ¶ˆæ¯
        messages = [
            {"role": "system", "content": prompt}
        ]
        messages.extend(chat_messages)

        # è®°å½•Ollamaè¾“å…¥
        logger.info(f"[{request_id}] ===== OLLAMAè¾“å…¥ =============================")
        logger.info(f"[{request_id}] æ¨¡å‹: {orchestra_state.selected_model}")
        logger.info(f"[{request_id}] ç³»ç»ŸPrompt: {prompt}")
        logger.info(f"[{request_id}] å¯¹è¯å†å²æ¶ˆæ¯æ•°: {len(chat_messages)}")
        logger.info(f"[{request_id}] ================================================")

        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/chat",
                json={
                    "model": orchestra_state.selected_model,
                    "messages": messages,
                    "stream": False
                },
                timeout=1000.0
            )

            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"[{request_id}] APIè°ƒç”¨è€—æ—¶: {duration:.2f}ç§’")

            if response.status_code == 200:
                result = response.json()
                response_text = result.get("message", {}).get("content", "")

                # è®°å½•å“åº”è¯¦æƒ…ï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼‰
                logger.info(f"[{request_id}] ===== OLLAMAè¾“å‡º =============================")
                logger.info(f"[{request_id}] å“åº”é•¿åº¦: {len(response_text)}å­—ç¬¦")
                logger.info(f"[{request_id}] è¾“å‡ºå†…å®¹: {response_text}")
                logger.info(f"[{request_id}] ================================================")

                # è®°å½•é¢å¤–çš„å“åº”ä¿¡æ¯
                if 'eval_count' in result:
                    logger.info(f"[{request_id}] Tokenç»Ÿè®¡ - è¾“å‡º: {result.get('eval_count', 0)}, è¾“å…¥: {result.get('prompt_eval_count', 0)}")
                if 'total_duration' in result:
                    total_duration_sec = result['total_duration'] / 1e9
                    logger.info(f"[{request_id}] æ€»å¤„ç†æ—¶é—´: {total_duration_sec:.2f}ç§’")

                return response_text
            else:
                error_msg = f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}"
                logger.error(f"[{request_id}] {error_msg} - å“åº”å†…å®¹: {response.text}")

                error_message = Message(
                    id=str(uuid.uuid4()),
                    role=RoleType.ETHER,
                    message_type=MessageType.ERROR,
                    content=error_msg,
                    timestamp=datetime.now()
                )
                await broadcast_message(error_message)
                return None

    except Exception as e:
        error_msg = f"è°ƒç”¨Ollama APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(f"[{request_id}] {error_msg}", exc_info=True)

        error_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.ERROR,
            content=error_msg,
            timestamp=datetime.now()
        )
        await broadcast_message(error_message)
        return None

async def ensure_summary_updated():
    """ç¡®ä¿æ€»ç»“æ˜¯æœ€æ–°çš„ï¼Œå¦‚æœéœ€è¦åˆ™ç”Ÿæˆæ–°æ€»ç»“"""
    messages_since_last_summary = get_messages_since_last_summary()

    # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œæˆ–è‡ªä¸Šæ¬¡æ€»ç»“åæœ‰æ–°æ¶ˆæ¯ï¼Œåˆ™ç”Ÿæˆæ–°æ€»ç»“
    if not orchestra_state.conversation_summaries or len(messages_since_last_summary) > 0:
        logger.info("æ£€æµ‹åˆ°éœ€è¦æ›´æ–°æ€»ç»“ï¼Œå¼€å§‹ç”Ÿæˆ...")
        await generate_conversation_summary()

def get_messages_since_last_summary() -> List[Message]:
    """è·å–è‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯"""
    if not orchestra_state.conversation_summaries:
        return orchestra_state.messages

    # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“çš„æ—¶é—´æ ‡è®°
    last_summary_time = None
    for msg in reversed(orchestra_state.messages):
        if (msg.role == RoleType.ETHER and
            msg.message_type == MessageType.SYSTEM_INFO and
            "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
            last_summary_time = msg.timestamp
            break

    if last_summary_time:
        return [msg for msg in orchestra_state.messages if msg.timestamp > last_summary_time]
    else:
        return orchestra_state.messages

async def generate_conversation_summary():
    """ç”Ÿæˆå¯¹è¯æ€»ç»“"""
    try:
        if len(orchestra_state.messages) < 4:  # æ¶ˆæ¯å¤ªå°‘ä¸éœ€è¦æ€»ç»“
            return

        logger.info("å¼€å§‹ç”Ÿæˆå¯¹è¯æ€»ç»“")

        # è·å–å½“å‰å¯¹è¯æ®µè½çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆè‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯ï¼‰
        if orchestra_state.conversation_summaries:
            # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯
            last_summary_time = None
            for msg in reversed(orchestra_state.messages):
                if (msg.role == RoleType.ETHER and
                    msg.message_type == MessageType.SYSTEM_INFO and
                    "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
                    last_summary_time = msg.timestamp
                    break

            if last_summary_time:
                current_conversation = [msg for msg in orchestra_state.messages if msg.timestamp > last_summary_time]
            else:
                current_conversation = orchestra_state.messages[-20:]  # å¦‚æœæ‰¾ä¸åˆ°æ ‡è®°ï¼Œä½¿ç”¨æœ€è¿‘20æ¡
        else:
            # ç¬¬ä¸€æ¬¡æ€»ç»“ï¼Œä½¿ç”¨æ‰€æœ‰æ¶ˆæ¯
            current_conversation = orchestra_state.messages

        # å¦‚æœæ¶ˆæ¯å¤ªå°‘ï¼Œä¸ç”Ÿæˆæ€»ç»“
        if len(current_conversation) < 3:
            logger.info(f"å½“å‰å¯¹è¯æ®µè½æ¶ˆæ¯å¤ªå°‘({len(current_conversation)}æ¡)ï¼Œè·³è¿‡æ€»ç»“")
            return

        recent_messages = current_conversation

        # æ„å»ºæ€»ç»“æç¤ºè¯ï¼Œè¿‡æ»¤æ‰ä»¥å¤ª(ç³»ç»Ÿ)æ¶ˆæ¯
        messages_text = []
        for msg in recent_messages:
            # è·³è¿‡ä»¥å¤ª(ç³»ç»Ÿ)çš„æ¶ˆæ¯ï¼Œåªä¿ç•™å®é™…å¯¹è¯
            if msg.role == RoleType.ETHER:
                continue
            role_name = get_role_display_name(msg.role)
            timestamp = msg.timestamp.strftime("%H:%M:%S")
            messages_text.append(f"[{timestamp}] {role_name}: {msg.content}")

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„æ€»ç»“ï¼Œå¦‚æœæœ‰ï¼Œåˆ™ç”Ÿæˆå¢é‡æ€»ç»“
        previous_summary = ""
        if orchestra_state.conversation_summaries:
            latest_summary = list(orchestra_state.conversation_summaries.values())[-1]
            previous_summary = f"""
ä¹‹å‰çš„å¯¹è¯æ€»ç»“ï¼š
{latest_summary}

---
"""

        summary_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯æ€»ç»“AIï¼Œéœ€è¦ä¸ºå¤šAIåä½œç³»ç»Ÿç”Ÿæˆç®€æ´æœ‰æ•ˆçš„å¯¹è¯æ€»ç»“ã€‚è¿™ä¸ªæ€»ç»“å°†ä½œä¸ºAIå¯¹è¯æ—¶çš„ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„èŠå¤©å†å²ã€‚

{previous_summary}
æœ¬æ¬¡æ–°å¢å¯¹è¯å†…å®¹ï¼š
{chr(10).join(messages_text)}

æ€»ç»“ç›®æ ‡ï¼š
ç”Ÿæˆä¸€ä¸ªç®€æ´ä½†ä¿¡æ¯å®Œæ•´çš„æ€»ç»“ï¼Œç”¨äºæ›¿ä»£å®Œæ•´çš„èŠå¤©å†å²ï¼Œè®©AIèƒ½å¤Ÿç†è§£ï¼š
1. **å½“å‰é¡¹ç›®çŠ¶æ€**ï¼šéœ€æ±‚ç¡®è®¤æƒ…å†µã€è®¾è®¡è¿›å±•ã€å¼€å‘çŠ¶æ€
2. **å…³é”®æŠ€æœ¯å†³ç­–**ï¼šæ¶æ„é€‰æ‹©ã€æŠ€æœ¯æ ˆã€è®¾è®¡åŸåˆ™
3. **é‡è¦çº¦æŸæ¡ä»¶**ï¼šç”¨æˆ·è¦æ±‚ã€æŠ€æœ¯é™åˆ¶ã€ä¸šåŠ¡è§„åˆ™
4. **å¾…è§£å†³é—®é¢˜**ï¼šå½“å‰é˜»å¡ç‚¹ã€éœ€è¦æ¾„æ¸…çš„é—®é¢˜
5. **ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼šæ˜ç¡®çš„åç»­ä»»åŠ¡å’Œè´£ä»»åˆ†å·¥

æ€»ç»“è¦æ±‚ï¼š
- ä¿æŒå®¢è§‚äº‹å®ï¼Œé¿å…å†—ä½™æè¿°
- çªå‡ºæ ¸å¿ƒä¿¡æ¯ï¼Œå¿½ç•¥å®¢å¥—è¯
- ä½¿ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼
- ç¡®ä¿AIèƒ½åŸºäºæ­¤æ€»ç»“ç»§ç»­åä½œ
- æ€»ç»“é•¿åº¦æ§åˆ¶åœ¨500å­—ä»¥å†…

è¯·ç”Ÿæˆç»“æ„åŒ–æ€»ç»“ï¼š
"""

        # è°ƒç”¨AIç”Ÿæˆæ€»ç»“ï¼ˆæ€»ç»“AIéœ€è¦ç‰¹æ®Šçš„ä¸Šä¸‹æ–‡å¤„ç†ï¼‰
        summary = await call_ollama_api_for_summary(summary_prompt)

        if summary:
            # ä¿å­˜æ€»ç»“
            summary_key = f"summary_{len(orchestra_state.messages)}"
            orchestra_state.conversation_summaries[summary_key] = summary

            logger.info(f"å¯¹è¯æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œä¿å­˜ä¸º {summary_key}")
            logger.info(f"æ€»ç»“å†…å®¹: {summary}")

            # å°†æ€»ç»“å†…å®¹ä½œä¸ºETHERæ¶ˆæ¯å±•ç¤ºåœ¨ç•Œé¢ä¸Š
            summary_display_message = Message(
                id=str(uuid.uuid4()),
                role=RoleType.ETHER,
                message_type=MessageType.SYSTEM_INFO,
                content=f"ğŸ“‹ **å¯¹è¯æ€»ç»“**\n\n{summary}",
                timestamp=datetime.now()
            )
            # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½è°ƒç”¨broadcast_messageï¼Œä¼šå¯¼è‡´é€’å½’
            orchestra_state.messages.append(summary_display_message)

            # ç›´æ¥å‘é€ç»™å®¢æˆ·ç«¯å±•ç¤ºæ€»ç»“å†…å®¹
            for websocket in orchestra_state.websocket_connections:
                try:
                    await websocket.send_text(json.dumps({
                        "type": "new_message",
                        "message": summary_display_message.model_dump(mode="json")
                    }))
                except:
                    pass

        else:
            logger.error("å¯¹è¯æ€»ç»“ç”Ÿæˆå¤±è´¥")

    except Exception as e:
        logger.error(f"ç”Ÿæˆå¯¹è¯æ€»ç»“æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)

async def call_ollama_api_for_summary(prompt: str) -> Optional[str]:
    """ä¸“é—¨ç”¨äºè°ƒç”¨æ€»ç»“AIçš„å‡½æ•°ï¼Œä¸è§¦å‘æ€»ç»“æ›´æ–°"""
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] å¼€å§‹è°ƒç”¨æ€»ç»“AI - æ¨¡å‹: {orchestra_state.selected_model}")

    try:
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": orchestra_state.selected_model,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=1000.0
            )

            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"[{request_id}] æ€»ç»“APIè°ƒç”¨è€—æ—¶: {duration:.2f}ç§’")

            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "")

                logger.info(f"[{request_id}] æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response_text)}å­—ç¬¦")
                return response_text
            else:
                error_msg = f"æ€»ç»“AIè°ƒç”¨å¤±è´¥: {response.status_code}"
                logger.error(f"[{request_id}] {error_msg}")
                return None

    except Exception as e:
        error_msg = f"è°ƒç”¨æ€»ç»“AIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(f"[{request_id}] {error_msg}", exc_info=True)
        return None

@app.get("/api/models")
async def get_available_models():
    logger.info("æ­£åœ¨è·å–å¯ç”¨çš„Ollamaæ¨¡å‹åˆ—è¡¨")
    try:
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:11434/api/tags", timeout=1000.0)
            duration = (datetime.now() - start_time).total_seconds()

            if response.status_code == 200:
                data = response.json()
                models = [model["name"] for model in data.get("models", [])]
                logger.info(f"æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨ (è€—æ—¶ {duration:.2f}ç§’): {models}")
                logger.info(f"å½“å‰é€‰ä¸­æ¨¡å‹: {orchestra_state.selected_model}")
                return {"models": models, "selected": orchestra_state.selected_model}
            else:
                logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ - HTTP {response.status_code}: {response.text}")
                return {"models": [""], "selected": orchestra_state.selected_model, "error": "Failed to fetch models"}
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return {"models": [""], "selected": orchestra_state.selected_model, "error": str(e)}

class ModelSelection(BaseModel):
    model_name: str

@app.post("/api/select_model")
async def select_model(model_data: ModelSelection):
    old_model = orchestra_state.selected_model
    new_model = model_data.model_name

    logger.info(f"æ¨¡å‹åˆ‡æ¢è¯·æ±‚: {old_model} -> {new_model}")

    orchestra_state.selected_model = new_model

    logger.info(f"æ¨¡å‹å·²æˆåŠŸåˆ‡æ¢ä¸º: {new_model}")

    return {"status": "success", "selected_model": new_model}

@app.get("/")
async def serve_frontend():
    return FileResponse("static/index.html")

app.mount("/static", StaticFiles(directory="static"), name="static")

def is_port_available(port: int) -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨"""
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.bind(('0.0.0.0', port))
            return True
    except OSError:
        return False

def find_available_port(start_port: int = 8000, max_attempts: int = 100) -> int:
    """æŸ¥æ‰¾å¯ç”¨çš„éšæœºç«¯å£"""
    # å…ˆå°è¯•é»˜è®¤ç«¯å£
    if is_port_available(start_port):
        return start_port
    
    # å¦‚æœé»˜è®¤ç«¯å£ä¸å¯ç”¨ï¼Œéšæœºé€‰æ‹©ç«¯å£
    for _ in range(max_attempts):
        port = random.randint(8000, 9999)
        if is_port_available(port):
            return port
    
    # å¦‚æœéšæœºç«¯å£éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ç³»ç»Ÿåˆ†é…
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.bind(('0.0.0.0', 0))
        return sock.getsockname()[1]

if __name__ == "__main__":
    import uvicorn
    logger.info("å¯åŠ¨OrchestraAIå¤šAIåä½œå¹³å°")
    logger.info(f"é»˜è®¤é€‰æ‹©æ¨¡å‹: {orchestra_state.selected_model}")
    
    port = find_available_port()
    logger.info(f"æ‰¾åˆ°å¯ç”¨ç«¯å£: {port}")
    logger.info(f"æœåŠ¡å™¨å°†åœ¨ http://0.0.0.0:{port} å¯åŠ¨")
    uvicorn.run(app, host="0.0.0.0", port=port)