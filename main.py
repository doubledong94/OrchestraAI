from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import asyncio
import httpx
import os
from datetime import datetime
import uuid
from enum import Enum
import logging

app = FastAPI(title="OrchestraAI", description="Multi-AI Collaboration Platform")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('orchestra_ai.log')
    ]
)
logger = logging.getLogger(__name__)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class RoleType(str, Enum):
    HUMAN = "human"
    ETHER = "ether"
    PRODUCT_AI = "product_ai"
    ARCHITECT_AI = "architect_ai"
    INTERFACE_AI = "interface_ai"
    PROGRAMMER_AI = "programmer_ai"

class MessageType(str, Enum):
    USER_INPUT = "user_input"
    AI_RESPONSE = "ai_response"
    SYSTEM_INFO = "system_info"
    FILE_SAVED = "file_saved"
    ERROR = "error"

class Message(BaseModel):
    id: str
    role: RoleType
    message_type: MessageType
    content: str
    timestamp: datetime
    metadata: Optional[Dict[str, Any]] = None

class TaskStatus(str, Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    BLOCKED = "blocked"

class Task(BaseModel):
    id: str
    title: str
    description: str
    status: TaskStatus
    assignee: RoleType
    dependencies: List[str] = []
    created_at: datetime
    updated_at: datetime

class OrchestraState:
    def __init__(self):
        self.messages: List[Message] = []
        self.tasks: Dict[str, Task] = {}
        self.current_requirement: Optional[str] = None
        self.requirement_confirmed: bool = False
        self.websocket_connections: List[WebSocket] = []
        self.file_outputs: List[str] = []
        self.selected_model: str = "llama3.1:8b"
        self.max_context_messages: int = 20  # æœ€å¤§ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°é‡
        self.max_context_length: int = 8000  # æœ€å¤§ä¸Šä¸‹æ–‡å­—ç¬¦é•¿åº¦
        self.conversation_summaries: Dict[str, str] = {}  # å„é˜¶æ®µçš„å¯¹è¯æ€»ç»“
        self.summary_trigger_count: int = 6  # æ¯6æ¡æ¶ˆæ¯è§¦å‘ä¸€æ¬¡æ€»ç»“
    
    def get_context_for_role(self, role: RoleType, max_messages: Optional[int] = None) -> str:
        """è·å–ç‰¹å®šè§’è‰²çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåªä½¿ç”¨æ€»ç»“ï¼‰"""
        # å¦‚æœæœ‰æ€»ç»“ï¼Œç›´æ¥è¿”å›æœ€æ–°çš„æ€»ç»“
        if self.conversation_summaries:
            latest_summary = list(self.conversation_summaries.values())[-1]
            logger.info(f"ä¸ºè§’è‰² {role.value} æä¾›æ€»ç»“ä¸Šä¸‹æ–‡ï¼Œæ€»ç»“é•¿åº¦: {len(latest_summary)}")
            return latest_summary
        else:
            # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè®©AIåŸºäºå½“å‰æç¤ºè¯å·¥ä½œ
            logger.info(f"ä¸ºè§’è‰² {role.value} æä¾›ç©ºä¸Šä¸‹æ–‡ï¼ˆæ— æ€»ç»“ï¼‰")
            return ""
    
    def get_current_conversation_messages_for_role(self, role: RoleType) -> List[Message]:
        """è·å–å½“å‰å¯¹è¯æ®µè½çš„æ¶ˆæ¯ï¼ˆè‡ªæœ€åä¸€æ¬¡æ€»ç»“åï¼‰"""
        if not self.conversation_summaries:
            # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œè¿”å›æ‰€æœ‰æ¶ˆæ¯
            return self.get_recent_messages_for_role(role, len(self.messages))
        
        # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“åçš„æ¶ˆæ¯
        last_summary_time = None
        if self.conversation_summaries:
            # å¯»æ‰¾æœ€åä¸€ä¸ªæ€»ç»“ç”Ÿæˆæ—¶é—´çš„æ ‡è®°
            for msg in reversed(self.messages):
                if (msg.role == RoleType.ETHER and 
                    msg.message_type == MessageType.SYSTEM_INFO and
                    "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
                    last_summary_time = msg.timestamp
                    break
        
        if last_summary_time:
            # è¿”å›æœ€åæ€»ç»“æ—¶é—´ä¹‹åçš„æ¶ˆæ¯
            current_messages = []
            for msg in self.messages:
                if msg.timestamp > last_summary_time:
                    current_messages.append(msg)
            return self.filter_messages_by_role_relevance(current_messages, role)
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°æ€»ç»“æ—¶é—´æ ‡è®°ï¼Œè¿”å›æœ€è¿‘çš„æ¶ˆæ¯
            return self.get_recent_messages_for_role(role, self.max_context_messages)
    
    def filter_important_messages_for_role(self, messages: List[Message], role: RoleType, max_count: int) -> List[Message]:
        """ç­›é€‰è§’è‰²ç›¸å…³çš„é‡è¦æ¶ˆæ¯"""
        # æŒ‰é‡è¦æ€§æ’åºï¼šç”¨æˆ·è¾“å…¥ > AIå›å¤ > ç³»ç»Ÿæ¶ˆæ¯ > é”™è¯¯æ¶ˆæ¯
        importance_order = {
            MessageType.USER_INPUT: 1,
            MessageType.AI_RESPONSE: 2,
            MessageType.SYSTEM_INFO: 3,
            MessageType.ERROR: 4,
            MessageType.FILE_SAVED: 5
        }
        
        role_messages = self.filter_messages_by_role_relevance(messages, role)
        
        # æŒ‰é‡è¦æ€§å’Œæ—¶é—´æ’åº
        sorted_messages = sorted(role_messages, 
                               key=lambda x: (importance_order.get(x.message_type, 10), -x.timestamp.timestamp()))
        
        return sorted_messages[:max_count]
    
    def filter_messages_by_role_relevance(self, messages: List[Message], role: RoleType) -> List[Message]:
        """æ ¹æ®è§’è‰²ç›¸å…³æ€§è¿‡æ»¤æ¶ˆæ¯"""
        if role == RoleType.PRODUCT_AI:
            return [msg for msg in messages if msg.role in [RoleType.HUMAN, RoleType.PRODUCT_AI, RoleType.ETHER]]
        elif role == RoleType.ARCHITECT_AI:
            return [msg for msg in messages if msg.role in [RoleType.HUMAN, RoleType.PRODUCT_AI, RoleType.ARCHITECT_AI, RoleType.ETHER]]
        elif role == RoleType.INTERFACE_AI:
            return [msg for msg in messages if msg.role in [RoleType.HUMAN, RoleType.PRODUCT_AI, RoleType.ARCHITECT_AI, RoleType.INTERFACE_AI, RoleType.ETHER]]
        elif role == RoleType.PROGRAMMER_AI:
            return [msg for msg in messages if msg.message_type != MessageType.SYSTEM_INFO or msg.role == RoleType.ETHER]
        else:
            return messages

    def get_recent_messages_for_role(self, role: RoleType, max_count: int) -> List[Message]:
        """è·å–è§’è‰²ç›¸å…³çš„æœ€è¿‘æ¶ˆæ¯"""
        relevant_messages = []
        
        # æ ¹æ®è§’è‰²ç±»å‹é€‰æ‹©ä¸åŒçš„æ¶ˆæ¯èŒƒå›´
        if role == RoleType.PRODUCT_AI:
            # äº§å“AIéœ€è¦çœ‹åˆ°ï¼šäººç±»è¾“å…¥ + è‡ªå·±çš„å†å²å›å¤
            for msg in reversed(self.messages):
                if (msg.role == RoleType.HUMAN or 
                    msg.role == RoleType.PRODUCT_AI):
                    relevant_messages.insert(0, msg)
                if len(relevant_messages) >= max_count:
                    break
                    
        elif role == RoleType.ARCHITECT_AI:
            # æ¶æ„AIéœ€è¦çœ‹åˆ°ï¼šäººç±»è¾“å…¥ + äº§å“AIçš„åˆ†æ + è‡ªå·±çš„å†å²å›å¤
            for msg in reversed(self.messages):
                if (msg.role == RoleType.HUMAN or 
                    msg.role == RoleType.PRODUCT_AI or
                    msg.role == RoleType.ARCHITECT_AI):
                    relevant_messages.insert(0, msg)
                if len(relevant_messages) >= max_count:
                    break
                    
        elif role == RoleType.INTERFACE_AI:
            # æ¥å£AIéœ€è¦çœ‹åˆ°ï¼šäººç±»è¾“å…¥ + äº§å“AIåˆ†æ + æ¶æ„AIè®¾è®¡ + è‡ªå·±çš„å†å²å›å¤
            for msg in reversed(self.messages):
                if (msg.role == RoleType.HUMAN or 
                    msg.role == RoleType.PRODUCT_AI or
                    msg.role == RoleType.ARCHITECT_AI or
                    msg.role == RoleType.INTERFACE_AI):
                    relevant_messages.insert(0, msg)
                if len(relevant_messages) >= max_count:
                    break
                    
        elif role == RoleType.PROGRAMMER_AI:
            # ç¨‹åºå‘˜AIéœ€è¦çœ‹åˆ°ï¼šå…¨éƒ¨ç›¸å…³æ¶ˆæ¯ï¼ˆé™¤äº†ç³»ç»Ÿæ¶ˆæ¯ï¼‰
            for msg in reversed(self.messages):
                if msg.message_type != MessageType.SYSTEM_INFO:
                    relevant_messages.insert(0, msg)
                if len(relevant_messages) >= max_count:
                    break
        else:
            # é»˜è®¤æƒ…å†µï¼šæ‰€æœ‰æœ€è¿‘æ¶ˆæ¯
            relevant_messages = self.messages[-max_count:]
        
        return relevant_messages

    def get_compressed_context_for_role(self, role: RoleType) -> str:
        """è·å–å‹ç¼©çš„ä¸Šä¸‹æ–‡ï¼ˆä»…æ€»ç»“ + æœ€å…³é”®çš„æœ€è¿‘æ¶ˆæ¯ï¼‰"""
        context_parts = []
        
        # æ·»åŠ æœ€æ–°çš„æ€»ç»“
        if self.conversation_summaries:
            latest_summary = list(self.conversation_summaries.values())[-1]
            context_parts.append(f"ã€å¯¹è¯æ€»ç»“ã€‘{latest_summary}")
            context_parts.append("---")
        
        # åªæ·»åŠ æœ€å…³é”®çš„æœ€è¿‘æ¶ˆæ¯ï¼ˆæœ€å3-5æ¡ï¼‰
        key_messages = self.get_recent_messages_for_role(role, 5)
        for msg in key_messages[-3:]:  # åªå–æœ€å3æ¡
            role_name = self.get_role_display_name(msg.role)
            timestamp = msg.timestamp.strftime("%H:%M:%S")
            context_parts.append(f"[{timestamp}] {role_name}: {msg.content}")
        
        return "\n".join(context_parts)
    
    def get_role_display_name(self, role: RoleType) -> str:
        """è·å–è§’è‰²æ˜¾ç¤ºåç§°"""
        role_names = {
            RoleType.HUMAN: "äººç±»ç”¨æˆ·",
            RoleType.ETHER: "ç³»ç»Ÿ",
            RoleType.PRODUCT_AI: "äº§å“AI",
            RoleType.ARCHITECT_AI: "æ¶æ„AI", 
            RoleType.INTERFACE_AI: "æ¥å£AI",
            RoleType.PROGRAMMER_AI: "ç¨‹åºå‘˜AI"
        }
        return role_names.get(role, role.value)

orchestra_state = OrchestraState()

AI_PROMPTS = {
    RoleType.PRODUCT_AI: """
ä½ æ˜¯äº§å“AIï¼Œè´Ÿè´£éœ€æ±‚åˆ†æå’Œäº§å“è®¾è®¡ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š

**ç¬¬ä¸€é˜¶æ®µ - éœ€æ±‚æ”¶é›†**ï¼š
1. æ”¶åˆ°äººç±»çš„åˆå§‹éœ€æ±‚åï¼Œå‘äººç±»æå‡ºå…·ä½“çš„é—®é¢˜æ¥æ˜ç¡®éœ€æ±‚ç»†èŠ‚
2. é—®é¢˜è¦å…·ä½“ï¼Œæœ€å¥½æ˜¯é€‰æ‹©é¢˜ï¼Œé¿å…æ¨¡ç³Šé—®é¢˜
3. æ˜ç¡®éœ€æ±‚çš„å“ªäº›æ–¹é¢æ˜¯äººç±»åœ¨ä¹çš„ï¼Œå“ªäº›æ˜¯æ— æ‰€è°“çš„
4. æ¯æ¬¡å›å¤éƒ½è¦è¯„ä¼°ï¼šæ˜¯å¦å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯æ¥è®¾è®¡äº§å“

**ç¬¬äºŒé˜¶æ®µ - éœ€æ±‚ç¡®è®¤ä¸æ€»ç»“**ï¼š
å½“ä½ è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯æ—¶ï¼Œå¿…é¡»ï¼š
1. æ˜ç¡®å£°æ˜ï¼š"åŸºäºæˆ‘ä»¬çš„å¯¹è¯ï¼Œæˆ‘è®¤ä¸ºå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„äº§å“éœ€æ±‚ä¿¡æ¯"
2. æä¾›å®Œæ•´çš„éœ€æ±‚æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
   - æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚
   - ç”¨æˆ·è§’è‰²å’Œæƒé™
   - å…³é”®ä¸šåŠ¡æµç¨‹
   - æŠ€æœ¯è¦æ±‚å’Œçº¦æŸ
   - ä¼˜å…ˆçº§è¯´æ˜
3. è¯¢é—®ç”¨æˆ·ï¼š"è¯·ç¡®è®¤ä»¥ä¸Šéœ€æ±‚æ€»ç»“æ˜¯å¦å®Œæ•´å‡†ç¡®ï¼Ÿå¦‚æœç¡®è®¤æ— è¯¯ï¼Œæˆ‘å°†æŠŠéœ€æ±‚ç§»äº¤ç»™æ¶æ„AIè¿›è¡ŒæŠ€æœ¯è®¾è®¡ã€‚"

**é‡è¦åŸåˆ™**ï¼š
- ä¸è¦æ— é™åˆ¶åœ°é—®é—®é¢˜ï¼Œé€šå¸¸3-5è½®å¯¹è¯åº”è¯¥èƒ½æ”¶é›†åˆ°åŸºæœ¬ä¿¡æ¯
- è¦ä¸»åŠ¨åˆ¤æ–­ä½•æ—¶ä¿¡æ¯å·²ç»è¶³å¤Ÿè¿›è¡Œäº§å“è®¾è®¡
- å¦‚æœé‡åˆ°æ— æ³•è§£å†³çš„é—®é¢˜ï¼ŒåŠæ—¶ä¸ŠæŠ¥ç»™äººç±»
- ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€ä¸äººç±»æ²Ÿé€š

**å›å¤æ ¼å¼æŒ‡å¯¼**ï¼š
- å¦‚æœè¿˜éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œç»§ç»­æé—®
- å¦‚æœä¿¡æ¯è¶³å¤Ÿï¼Œä½¿ç”¨"ã€éœ€æ±‚ç¡®è®¤ã€‘"æ ‡è®°å¼€å§‹éœ€æ±‚æ€»ç»“
""",
    
    RoleType.ARCHITECT_AI: """
ä½ æ˜¯æ¶æ„AIï¼Œè´Ÿè´£æŠ€æœ¯æ¶æ„è®¾è®¡å’Œä»»åŠ¡åˆ†è§£ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. ä»ä»£ç å®ç°è§’åº¦å°†äº§å“éœ€æ±‚è½¬æ¢ä¸ºå…·ä½“çš„å®ç°æ­¥éª¤
2. ç¡®å®šå“ªäº›æ­¥éª¤èƒ½å¹¶è¡Œæ‰§è¡Œï¼Œå“ªäº›æœ‰ä¾èµ–å…³ç³»
3. å°†æœ‰ä¾èµ–å…³ç³»çš„æ­¥éª¤äº¤ç»™æ¥å£AIè®¾è®¡æ¥å£
4. è®¾è®¡æ–‡ä»¶ç›®å½•ç»“æ„ï¼Œç¡®å®šä»£ç æ–‡ä»¶çš„å­˜æ”¾ä½ç½®
5. å°†å¯æ‰§è¡Œçš„ä»»åŠ¡åˆ†é…ç»™ç¨‹åºå‘˜AI
6. æ”¶é›†å¹¶æ‹¼æ¥ç¨‹åºå‘˜AIçš„ä»£ç ï¼Œé€šè¿‡ä»¥å¤ªä¿å­˜æ–‡ä»¶

è¯·ç¡®ä¿æ¶æ„è®¾è®¡åˆç†ï¼Œä»»åŠ¡åˆ†è§£æ¸…æ™°ï¼Œä¾¿äºå¹¶è¡Œå¼€å‘ã€‚
""",
    
    RoleType.INTERFACE_AI: """
ä½ æ˜¯æ¥å£AIï¼Œè´Ÿè´£è®¾è®¡æ¨¡å—é—´çš„æ¥å£ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. ä¸ºæœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡è®¾è®¡æ¸…æ™°çš„æ¥å£è§„èŒƒ
2. å®šä¹‰æ•°æ®ç»“æ„ã€å‡½æ•°ç­¾åã€APIè§„èŒƒ
3. ç¡®ä¿æ¥å£è®¾è®¡ç¬¦åˆæœ€ä½³å®è·µï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
4. æä¾›è¯¦ç»†çš„æ¥å£æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

è¯·ç¡®ä¿æ¥å£è®¾è®¡è§„èŒƒã€ä¸€è‡´ï¼Œä¾¿äºä¸åŒæ¨¡å—çš„é›†æˆã€‚
""",
    
    RoleType.PROGRAMMER_AI: """
ä½ æ˜¯ç¨‹åºå‘˜AIï¼Œè´Ÿè´£å…·ä½“çš„ä»£ç å®ç°ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
1. æ ¹æ®æ¶æ„AIåˆ†é…çš„ä»»åŠ¡å®ç°å…·ä½“ä»£ç 
2. éµå¾ªæ¥å£AIè®¾è®¡çš„æ¥å£è§„èŒƒ
3. ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç 
4. åŒ…å«å¿…è¦çš„æ³¨é‡Šå’Œé”™è¯¯å¤„ç†
5. ç¡®ä¿ä»£ç ç¬¦åˆæœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ

è¯·ç¼–å†™æ¸…æ™°ã€é«˜æ•ˆçš„ä»£ç ï¼Œæ³¨é‡ä»£ç è´¨é‡å’Œå¯è¯»æ€§ã€‚
"""
}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    orchestra_state.websocket_connections.append(websocket)
    
    try:
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "messages": [msg.model_dump(mode="json") for msg in orchestra_state.messages[-50:]]
        }))
        
        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            if message_data["type"] == "human_input":
                await handle_human_input(message_data["content"])
            elif message_data["type"] == "interrupt":
                await handle_human_interrupt(message_data["content"])
                
    except WebSocketDisconnect:
        orchestra_state.websocket_connections.remove(websocket)

async def broadcast_message(message: Message):
    orchestra_state.messages.append(message)
    
    # æ£€æŸ¥äº§å“AIæ˜¯å¦å‘å‡ºäº†éœ€æ±‚ç¡®è®¤ä¿¡å·
    if (message.role == RoleType.PRODUCT_AI and 
        message.message_type == MessageType.AI_RESPONSE and
        "ã€éœ€æ±‚ç¡®è®¤ã€‘" in message.content):
        
        logger.info("æ£€æµ‹åˆ°äº§å“AIéœ€æ±‚ç¡®è®¤ä¿¡å·ï¼Œè‡ªåŠ¨å¯åŠ¨æ¶æ„AI")
        
        # æ ‡è®°éœ€æ±‚å·²ç¡®è®¤
        orchestra_state.requirement_confirmed = True
        orchestra_state.current_requirement = message.content
        
        # å‘é€æµç¨‹è½¬æ¢ç³»ç»Ÿæ¶ˆæ¯
        transition_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content="âœ… äº§å“AIå·²å®Œæˆéœ€æ±‚æ”¶é›†å’Œæ€»ç»“ï¼Œè‡ªåŠ¨å¯åŠ¨æ¶æ„è®¾è®¡é˜¶æ®µ...",
            timestamp=datetime.now()
        )
        orchestra_state.messages.append(transition_message)
        
        # å¹¿æ’­æµç¨‹è½¬æ¢æ¶ˆæ¯
        for websocket in orchestra_state.websocket_connections:
            try:
                await websocket.send_text(json.dumps({
                    "type": "new_message", 
                    "message": transition_message.model_dump(mode="json")
                }))
            except:
                pass
        
        # è‡ªåŠ¨è§¦å‘æ¶æ„AIï¼ˆå¼‚æ­¥æ‰§è¡Œé¿å…é˜»å¡ï¼‰
        import asyncio
        asyncio.create_task(auto_trigger_architect_ai(message.content))
    
    disconnected = []
    for websocket in orchestra_state.websocket_connections:
        try:
            await websocket.send_text(json.dumps({
                "type": "new_message",
                "message": message.model_dump(mode="json")
            }))
        except:
            disconnected.append(websocket)
    
    for ws in disconnected:
        orchestra_state.websocket_connections.remove(ws)

async def handle_human_input(content: str):
    logger.info(f"æ”¶åˆ°äººç±»è¾“å…¥: {content}")  # å®Œæ•´è®°å½•
    
    message = Message(
        id=str(uuid.uuid4()),
        role=RoleType.HUMAN,
        message_type=MessageType.USER_INPUT,
        content=content,
        timestamp=datetime.now()
    )
    
    await broadcast_message(message)
    
    if not orchestra_state.requirement_confirmed:
        logger.info("éœ€æ±‚å°šæœªç¡®è®¤ï¼Œè§¦å‘äº§å“AIåˆ†æ")
        await trigger_product_ai(content)
    else:
        logger.info("éœ€æ±‚å·²ç¡®è®¤ï¼Œç»§ç»­åç»­åä½œæµç¨‹")
        # éœ€æ±‚å·²ç¡®è®¤åï¼Œç”¨æˆ·çš„è¾“å…¥å¯ä»¥ç”¨äºæŒ‡å¯¼åç»­çš„AIåä½œ
        await handle_post_requirement_input(content)

def has_recent_product_confirmation() -> bool:
    """æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰äº§å“AIçš„éœ€æ±‚ç¡®è®¤"""
    # æ£€æŸ¥æœ€è¿‘5æ¡æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰äº§å“AIçš„éœ€æ±‚ç¡®è®¤
    recent_messages = orchestra_state.messages[-5:]
    for msg in recent_messages:
        if (msg.role == RoleType.PRODUCT_AI and 
            msg.message_type == MessageType.AI_RESPONSE and
            "ã€éœ€æ±‚ç¡®è®¤ã€‘" in msg.content):
            return True
    return False

async def handle_human_interrupt(content: str):
    message = Message(
        id=str(uuid.uuid4()),
        role=RoleType.HUMAN,
        message_type=MessageType.SYSTEM_INFO,
        content=f"ã€äººç±»æ‰“æ–­ã€‘{content}",
        timestamp=datetime.now()
    )
    
    await broadcast_message(message)

async def trigger_product_ai(user_input: str):
    logger.info(f"è§¦å‘äº§å“AIåˆ†æç”¨æˆ·éœ€æ±‚: {user_input}")  # å®Œæ•´è®°å½•
    
    # ç»Ÿè®¡äº§å“AIå’Œäººç±»çš„å¯¹è¯è½®æ•°æ¥åˆ¤æ–­æ˜¯å¦åº”è¯¥å¼€å§‹æ€»ç»“
    product_ai_messages = sum(1 for msg in orchestra_state.messages 
                             if msg.role == RoleType.PRODUCT_AI and msg.message_type == MessageType.AI_RESPONSE)
    
    if product_ai_messages >= 2:  # 2è½®å¯¹è¯åå¼€å§‹æé†’æ€»ç»“
        additional_instruction = """

**é‡è¦æé†’**: è¿™å·²ç»æ˜¯æˆ‘ä»¬çš„ç¬¬{}è½®å¯¹è¯äº†ã€‚è¯·è¯„ä¼°æ˜¯å¦å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„éœ€æ±‚ä¿¡æ¯ã€‚å¦‚æœæ˜¯ï¼Œè¯·ä½¿ç”¨"ã€éœ€æ±‚ç¡®è®¤ã€‘"æ ‡è®°å¼€å§‹éœ€æ±‚æ€»ç»“ã€‚""".format(product_ai_messages + 1)
    else:
        additional_instruction = ""
    
    prompt = f"""
{AI_PROMPTS[RoleType.PRODUCT_AI]}

ç”¨æˆ·è¾“å…¥ï¼š{user_input}

è¯·æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ç»§ç»­éœ€æ±‚åˆ†æã€‚å¦‚æœè¿™æ˜¯åˆå§‹éœ€æ±‚ï¼Œè¯·æå‡º3-5ä¸ªå…·ä½“çš„æ¾„æ¸…é—®é¢˜ã€‚å¦‚æœè¿™æ˜¯å¯¹ä¹‹å‰é—®é¢˜çš„å›ç­”ï¼Œè¯·åŸºäºå·²æœ‰ä¿¡æ¯ç»§ç»­æ·±å…¥äº†è§£æˆ–è€ƒè™‘æ˜¯å¦å¯ä»¥å¼€å§‹éœ€æ±‚æ€»ç»“ã€‚{additional_instruction}
"""
    
    response = await call_ollama_api(prompt, RoleType.PRODUCT_AI)
    if response:
        logger.info(f"äº§å“AIå“åº”ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response)}å­—ç¬¦")
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.PRODUCT_AI,
            message_type=MessageType.AI_RESPONSE,
            content=response,
            timestamp=datetime.now()
        )
        await broadcast_message(message)
    else:
        logger.error("äº§å“AIå“åº”ç”Ÿæˆå¤±è´¥")

async def trigger_architect_ai(requirement: str):
    logger.info(f"è§¦å‘æ¶æ„AIè®¾è®¡æŠ€æœ¯æ–¹æ¡ˆ: {requirement}")  # å®Œæ•´è®°å½•
    
    prompt = f"""
{AI_PROMPTS[RoleType.ARCHITECT_AI]}

äº§å“éœ€æ±‚ï¼š{requirement}

è¯·åˆ†æè¿™ä¸ªéœ€æ±‚å¹¶è¿›è¡ŒæŠ€æœ¯æ¶æ„è®¾è®¡ï¼š
1. åˆ†è§£ä¸ºå…·ä½“çš„å®ç°æ­¥éª¤
2. è¯†åˆ«æ­¥éª¤é—´çš„ä¾èµ–å…³ç³»
3. è®¾è®¡æ–‡ä»¶ç›®å½•ç»“æ„
4. åˆ¶å®šå¼€å‘è®¡åˆ’
"""
    
    response = await call_ollama_api(prompt, RoleType.ARCHITECT_AI)
    if response:
        logger.info(f"æ¶æ„AIæ–¹æ¡ˆè®¾è®¡æˆåŠŸï¼Œé•¿åº¦: {len(response)}å­—ç¬¦")
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ARCHITECT_AI,
            message_type=MessageType.AI_RESPONSE,
            content=response,
            timestamp=datetime.now()
        )
        await broadcast_message(message)
    else:
        logger.error("æ¶æ„AIæ–¹æ¡ˆè®¾è®¡å¤±è´¥")

async def call_ollama_api_for_summary(prompt: str) -> Optional[str]:
    """ä¸“é—¨ç”¨äºè°ƒç”¨æ€»ç»“AIçš„å‡½æ•°ï¼Œä¸è§¦å‘æ€»ç»“æ›´æ–°"""
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] å¼€å§‹è°ƒç”¨æ€»ç»“AI - æ¨¡å‹: {orchestra_state.selected_model}")
    
    try:
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": orchestra_state.selected_model,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=1000.0
            )
            
            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"[{request_id}] æ€»ç»“APIè°ƒç”¨è€—æ—¶: {duration:.2f}ç§’")
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "")
                
                logger.info(f"[{request_id}] æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response_text)}å­—ç¬¦")
                return response_text
            else:
                error_msg = f"æ€»ç»“AIè°ƒç”¨å¤±è´¥: {response.status_code}"
                logger.error(f"[{request_id}] {error_msg}")
                return None
                
    except Exception as e:
        error_msg = f"è°ƒç”¨æ€»ç»“AIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(f"[{request_id}] {error_msg}", exc_info=True)
        return None

async def call_ollama_api(prompt: str, role: RoleType, include_context: bool = True) -> Optional[str]:
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] å¼€å§‹Ollama APIè°ƒç”¨ - è§’è‰²: {role.value}, æ¨¡å‹: {orchestra_state.selected_model}")
    
    try:
        # å¦‚æœæ˜¯æœ‰è§’è‰²çš„AIï¼ˆä¸æ˜¯ETHERæ€»ç»“AIï¼‰ï¼Œå…ˆç”Ÿæˆ/æ›´æ–°æ€»ç»“
        if role != RoleType.ETHER and len(orchestra_state.messages) > 0:
            await ensure_summary_updated()
        
        ether_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content=f"æ­£åœ¨è°ƒç”¨Ollama APIä¸º{role.value}ç”Ÿæˆå“åº”...",
            timestamp=datetime.now()
        )
        await broadcast_message(ether_message)
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ï¼‰
        full_prompt = prompt
        if include_context and len(orchestra_state.messages) > 0:
            context = orchestra_state.get_context_for_role(role)
            if context:
                full_prompt = f"""ä»¥ä¸‹æ˜¯ç›¸å…³çš„å¯¹è¯å†å²ï¼š

{context}

---

åŸºäºä»¥ä¸Šå¯¹è¯å†å²ï¼Œè¯·å›åº”ä»¥ä¸‹è¯·æ±‚ï¼š

{prompt}

è¯·ç¡®ä¿ä½ çš„å›åº”è€ƒè™‘åˆ°ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œä¿æŒè¿è´¯æ€§ã€‚"""
                
                context_stats = {
                    "total_messages": len(orchestra_state.messages),
                    "context_length": len(context),
                    "context_lines": len(context.split('\n')) if context else 0
                }
                logger.info(f"[{request_id}] ä¸Šä¸‹æ–‡ç»Ÿè®¡: {json.dumps(context_stats, ensure_ascii=False)}")
        
        # è®°å½•Ollamaè¾“å…¥
        logger.info(f"[{request_id}] ===== OLLAMAè¾“å…¥ =============================")
        logger.info(f"[{request_id}] æ¨¡å‹: {orchestra_state.selected_model}")
        logger.info(f"[{request_id}] è¾“å…¥Prompt: {full_prompt}")
        logger.info(f"[{request_id}] ================================================")
        
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": orchestra_state.selected_model,
                    "prompt": full_prompt,
                    "stream": False
                },
                timeout=1000.0
            )
            
            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"[{request_id}] APIè°ƒç”¨è€—æ—¶: {duration:.2f}ç§’")
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get("response", "")
                
                # è®°å½•å“åº”è¯¦æƒ…ï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼‰
                logger.info(f"[{request_id}] ===== OLLAMAè¾“å‡º =============================")
                logger.info(f"[{request_id}] å“åº”é•¿åº¦: {len(response_text)}å­—ç¬¦")
                logger.info(f"[{request_id}] è¾“å‡ºå†…å®¹: {response_text}")
                logger.info(f"[{request_id}] ================================================")
                
                # è®°å½•é¢å¤–çš„å“åº”ä¿¡æ¯
                if 'eval_count' in result:
                    logger.info(f"[{request_id}] Tokenç»Ÿè®¡ - è¾“å‡º: {result.get('eval_count', 0)}, è¾“å…¥: {result.get('prompt_eval_count', 0)}")
                if 'total_duration' in result:
                    total_duration_sec = result['total_duration'] / 1e9
                    logger.info(f"[{request_id}] æ€»å¤„ç†æ—¶é—´: {total_duration_sec:.2f}ç§’")
                
                return response_text
            else:
                error_msg = f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}"
                logger.error(f"[{request_id}] {error_msg} - å“åº”å†…å®¹: {response.text}")
                
                error_message = Message(
                    id=str(uuid.uuid4()),
                    role=RoleType.ETHER,
                    message_type=MessageType.ERROR,
                    content=error_msg,
                    timestamp=datetime.now()
                )
                await broadcast_message(error_message)
                return None
                
    except Exception as e:
        error_msg = f"è°ƒç”¨Ollama APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(f"[{request_id}] {error_msg}", exc_info=True)
        
        error_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.ERROR,
            content=error_msg,
            timestamp=datetime.now()
        )
        await broadcast_message(error_message)
        return None

async def handle_confirmed_requirement_input(content: str):
    """å¤„ç†éœ€æ±‚ç¡®è®¤é˜¶æ®µçš„ç”¨æˆ·è¾“å…¥ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å‘åå…¼å®¹ï¼‰"""
    if "éœ€æ±‚ç¡®è®¤" in content or "å¼€å§‹å¼€å‘" in content or "ç¡®è®¤" in content:
        orchestra_state.requirement_confirmed = True
        orchestra_state.current_requirement = content
        
        # å‘é€ç¡®è®¤æ¶ˆæ¯
        confirmation_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content="âœ… éœ€æ±‚å·²ç¡®è®¤ï¼æ­£åœ¨å¯åŠ¨æ¶æ„è®¾è®¡é˜¶æ®µ...",
            timestamp=datetime.now()
        )
        await broadcast_message(confirmation_message)
        
        # è·å–äº§å“AIçš„éœ€æ±‚æ€»ç»“ä½œä¸ºæ¶æ„è®¾è®¡çš„è¾“å…¥
        requirement_summary = extract_requirement_summary()
        await trigger_architect_ai(requirement_summary or content)

async def handle_post_requirement_input(content: str):
    """å¤„ç†éœ€æ±‚ç¡®è®¤åçš„ç”¨æˆ·è¾“å…¥"""
    logger.info(f"éœ€æ±‚ç¡®è®¤åçš„ç”¨æˆ·è¾“å…¥: {content}")  # å®Œæ•´è®°å½•
    
    # ç”¨æˆ·å¯èƒ½æƒ³è¦ï¼š
    # 1. ä¿®æ”¹éœ€æ±‚
    # 2. æŒ‡å¯¼å½“å‰AIçš„å·¥ä½œ
    # 3. è¯¢é—®è¿›åº¦
    # 4. æ‰“æ–­å½“å‰æµç¨‹
    
    if any(keyword in content for keyword in ["ä¿®æ”¹", "æ›´æ”¹", "é‡æ–°", "ä¸å¯¹"]):
        # ç”¨æˆ·æƒ³è¦ä¿®æ”¹éœ€æ±‚ï¼Œé‡ç½®çŠ¶æ€
        logger.info("ç”¨æˆ·è¦æ±‚ä¿®æ”¹éœ€æ±‚ï¼Œé‡ç½®åä½œçŠ¶æ€")
        
        reset_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content="ğŸ”„ æ£€æµ‹åˆ°éœ€æ±‚ä¿®æ”¹è¯·æ±‚ï¼Œé‡ç½®åä½œçŠ¶æ€ï¼Œé‡æ–°å¼€å§‹éœ€æ±‚æ”¶é›†...",
            timestamp=datetime.now()
        )
        await broadcast_message(reset_message)
        
        # é‡ç½®çŠ¶æ€
        orchestra_state.requirement_confirmed = False
        orchestra_state.current_requirement = None
        
        # é‡æ–°è§¦å‘äº§å“AI
        await trigger_product_ai(content)
        
    else:
        # ç”¨æˆ·çš„æŒ‡å¯¼æ„è§ï¼Œå¯ä»¥ä¼ é€’ç»™å½“å‰æ´»è·ƒçš„AIè§’è‰²
        guidance_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.SYSTEM_INFO,
            content=f"ğŸ“ ç”¨æˆ·æŒ‡å¯¼æ„è§å·²è®°å½•: {content}",
            timestamp=datetime.now()
        )
        await broadcast_message(guidance_message)


def get_messages_since_last_summary() -> List[Message]:
    """è·å–è‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯"""
    if not orchestra_state.conversation_summaries:
        return orchestra_state.messages
    
    # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“çš„æ—¶é—´æ ‡è®°
    last_summary_time = None
    for msg in reversed(orchestra_state.messages):
        if (msg.role == RoleType.ETHER and 
            msg.message_type == MessageType.SYSTEM_INFO and
            "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
            last_summary_time = msg.timestamp
            break
    
    if last_summary_time:
        return [msg for msg in orchestra_state.messages if msg.timestamp > last_summary_time]
    else:
        return orchestra_state.messages

def is_conversation_endpoint(message: Message) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯å¯¹è¯ç»“æŸç‚¹"""
    # å¯¹è¯ç»“æŸçš„æ ‡å¿—ï¼š
    # 1. äº§å“AIå‘å‡ºéœ€æ±‚ç¡®è®¤
    # 2. æ¶æ„AIå®ŒæˆæŠ€æœ¯æ–¹æ¡ˆè®¾è®¡
    # 3. ç¨‹åºå‘˜AIå®Œæˆä»£ç å®ç°
    # 4. ç”¨æˆ·å‘å‡ºæ˜ç¡®çš„ç»“æŸæŒ‡ä»¤
    # 5. å‡ºç°é”™è¯¯æ¶ˆæ¯å
    # 6. æ–‡ä»¶ä¿å­˜å®Œæˆå
    
    if message.role == RoleType.PRODUCT_AI and "ã€éœ€æ±‚ç¡®è®¤ã€‘" in message.content:
        logger.info("æ£€æµ‹åˆ°äº§å“AIéœ€æ±‚ç¡®è®¤ï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
        return True
    
    if message.role == RoleType.ARCHITECT_AI and any(keyword in message.content for keyword in ["æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡å®Œæˆ", "æ¶æ„è®¾è®¡å®Œæˆ", "å¼€å‘è®¡åˆ’åˆ¶å®šå®Œæˆ"]):
        logger.info("æ£€æµ‹åˆ°æ¶æ„AIå®Œæˆè®¾è®¡ï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
        return True
    
    if message.role == RoleType.PROGRAMMER_AI and any(keyword in message.content for keyword in ["ä»£ç å®ç°å®Œæˆ", "ç¨‹åºå¼€å‘å®Œæˆ", "ä»£ç ç¼–å†™å®Œæˆ"]):
        logger.info("æ£€æµ‹åˆ°ç¨‹åºå‘˜AIå®Œæˆå®ç°ï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
        return True
    
    if message.role == RoleType.HUMAN and any(keyword in message.content for keyword in ["ç»“æŸ", "å®Œæˆ", "åœæ­¢", "è°¢è°¢", "å¥½çš„", "OK", "ok"]):
        logger.info("æ£€æµ‹åˆ°ç”¨æˆ·ç»“æŸæŒ‡ä»¤ï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
        return True
    
    if message.message_type == MessageType.ERROR:
        logger.info("æ£€æµ‹åˆ°é”™è¯¯æ¶ˆæ¯ï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
        return True
    
    if message.message_type == MessageType.FILE_SAVED:
        logger.info("æ£€æµ‹åˆ°æ–‡ä»¶ä¿å­˜å®Œæˆï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
        return True
    
    # æ£€æŸ¥æœ€è¿‘å‡ æ¡æ¶ˆæ¯ï¼Œå¦‚æœæ²¡æœ‰æ–°çš„AIå“åº”ï¼ˆè¶…è¿‡30ç§’ï¼‰ï¼Œä¹Ÿè§†ä¸ºå¯¹è¯ç»“æŸ
    if len(orchestra_state.messages) >= 3:
        recent_messages = orchestra_state.messages[-3:]
        last_ai_response = None
        for msg in reversed(recent_messages):
            if msg.message_type == MessageType.AI_RESPONSE:
                last_ai_response = msg
                break
        
        if last_ai_response:
            time_since_last_ai = (datetime.now() - last_ai_response.timestamp).total_seconds()
            if time_since_last_ai > 30:  # 30ç§’æ— AIå“åº”
                logger.info(f"æœ€åAIå“åº”å·²è¿‡å»{time_since_last_ai}ç§’ï¼Œæ ‡è®°ä¸ºå¯¹è¯ç»“æŸç‚¹")
                return True
    
    return False

def extract_requirement_summary() -> Optional[str]:
    """æå–äº§å“AIçš„éœ€æ±‚æ€»ç»“"""
    # ä»æœ€è¿‘çš„æ¶ˆæ¯ä¸­å¯»æ‰¾äº§å“AIçš„éœ€æ±‚ç¡®è®¤æ¶ˆæ¯
    for msg in reversed(orchestra_state.messages):
        if (msg.role == RoleType.PRODUCT_AI and 
            msg.message_type == MessageType.AI_RESPONSE and
            "ã€éœ€æ±‚ç¡®è®¤ã€‘" in msg.content):
            return msg.content
    return None

async def auto_trigger_architect_ai(requirement_summary: str):
    """è‡ªåŠ¨è§¦å‘æ¶æ„AIçš„å¼‚æ­¥å‡½æ•°"""
    try:
        # ç»™ç”¨æˆ·ä¸€ç‚¹æ—¶é—´çœ‹åˆ°æµç¨‹è½¬æ¢æ¶ˆæ¯
        await asyncio.sleep(1)
        
        logger.info("è‡ªåŠ¨è§¦å‘æ¶æ„AIå¼€å§‹æŠ€æœ¯è®¾è®¡")
        await trigger_architect_ai(requirement_summary)
        
    except Exception as e:
        logger.error(f"è‡ªåŠ¨è§¦å‘æ¶æ„AIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        # å‘é€é”™è¯¯æ¶ˆæ¯
        error_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.ERROR,
            content=f"âŒ è‡ªåŠ¨å¯åŠ¨æ¶æ„AIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
            timestamp=datetime.now()
        )
        await broadcast_message(error_message)

async def ensure_summary_updated():
    """ç¡®ä¿æ€»ç»“æ˜¯æœ€æ–°çš„ï¼Œå¦‚æœéœ€è¦åˆ™ç”Ÿæˆæ–°æ€»ç»“"""
    messages_since_last_summary = get_messages_since_last_summary()
    
    # å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œæˆ–è‡ªä¸Šæ¬¡æ€»ç»“åæœ‰æ–°æ¶ˆæ¯ï¼Œåˆ™ç”Ÿæˆæ–°æ€»ç»“
    if not orchestra_state.conversation_summaries or len(messages_since_last_summary) > 0:
        logger.info("æ£€æµ‹åˆ°éœ€è¦æ›´æ–°æ€»ç»“ï¼Œå¼€å§‹ç”Ÿæˆ...")
        await generate_conversation_summary()

async def generate_conversation_summary():
    """ç”Ÿæˆå¯¹è¯æ€»ç»“"""
    try:
        if len(orchestra_state.messages) < 4:  # æ¶ˆæ¯å¤ªå°‘ä¸éœ€è¦æ€»ç»“
            return
            
        logger.info("å¼€å§‹ç”Ÿæˆå¯¹è¯æ€»ç»“")
        
        # è·å–å½“å‰å¯¹è¯æ®µè½çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆè‡ªä¸Šæ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯ï¼‰
        if orchestra_state.conversation_summaries:
            # æ‰¾åˆ°æœ€åä¸€æ¬¡æ€»ç»“åçš„æ‰€æœ‰æ¶ˆæ¯
            last_summary_time = None
            for msg in reversed(orchestra_state.messages):
                if (msg.role == RoleType.ETHER and 
                    msg.message_type == MessageType.SYSTEM_INFO and
                    "å·²ç”Ÿæˆå¯¹è¯æ€»ç»“" in msg.content):
                    last_summary_time = msg.timestamp
                    break
            
            if last_summary_time:
                current_conversation = [msg for msg in orchestra_state.messages if msg.timestamp > last_summary_time]
            else:
                current_conversation = orchestra_state.messages[-20:]  # å¦‚æœæ‰¾ä¸åˆ°æ ‡è®°ï¼Œä½¿ç”¨æœ€è¿‘20æ¡
        else:
            # ç¬¬ä¸€æ¬¡æ€»ç»“ï¼Œä½¿ç”¨æ‰€æœ‰æ¶ˆæ¯
            current_conversation = orchestra_state.messages
        
        # å¦‚æœæ¶ˆæ¯å¤ªå°‘ï¼Œä¸ç”Ÿæˆæ€»ç»“
        if len(current_conversation) < 3:
            logger.info(f"å½“å‰å¯¹è¯æ®µè½æ¶ˆæ¯å¤ªå°‘({len(current_conversation)}æ¡)ï¼Œè·³è¿‡æ€»ç»“")
            return
        
        recent_messages = current_conversation
        
        # æ„å»ºæ€»ç»“æç¤ºè¯ï¼Œè¿‡æ»¤æ‰ä»¥å¤ª(ç³»ç»Ÿ)æ¶ˆæ¯
        messages_text = []
        for msg in recent_messages:
            # è·³è¿‡ä»¥å¤ª(ç³»ç»Ÿ)çš„æ¶ˆæ¯ï¼Œåªä¿ç•™å®é™…å¯¹è¯
            if msg.role == RoleType.ETHER:
                continue
            role_name = orchestra_state.get_role_display_name(msg.role)
            timestamp = msg.timestamp.strftime("%H:%M:%S")
            messages_text.append(f"[{timestamp}] {role_name}: {msg.content}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„æ€»ç»“ï¼Œå¦‚æœæœ‰ï¼Œåˆ™ç”Ÿæˆå¢é‡æ€»ç»“
        previous_summary = ""
        if orchestra_state.conversation_summaries:
            latest_summary = list(orchestra_state.conversation_summaries.values())[-1]
            previous_summary = f"""
ä¹‹å‰çš„å¯¹è¯æ€»ç»“ï¼š
{latest_summary}

---
"""

        summary_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è¯æ€»ç»“AIï¼Œéœ€è¦ä¸ºå¤šAIåä½œç³»ç»Ÿç”Ÿæˆç®€æ´æœ‰æ•ˆçš„å¯¹è¯æ€»ç»“ã€‚è¿™ä¸ªæ€»ç»“å°†ä½œä¸ºAIå¯¹è¯æ—¶çš„ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„èŠå¤©å†å²ã€‚

{previous_summary}
æœ¬æ¬¡æ–°å¢å¯¹è¯å†…å®¹ï¼š
{chr(10).join(messages_text)}

æ€»ç»“ç›®æ ‡ï¼š
ç”Ÿæˆä¸€ä¸ªç®€æ´ä½†ä¿¡æ¯å®Œæ•´çš„æ€»ç»“ï¼Œç”¨äºæ›¿ä»£å®Œæ•´çš„èŠå¤©å†å²ï¼Œè®©AIèƒ½å¤Ÿç†è§£ï¼š
1. **å½“å‰é¡¹ç›®çŠ¶æ€**ï¼šéœ€æ±‚ç¡®è®¤æƒ…å†µã€è®¾è®¡è¿›å±•ã€å¼€å‘çŠ¶æ€
2. **å…³é”®æŠ€æœ¯å†³ç­–**ï¼šæ¶æ„é€‰æ‹©ã€æŠ€æœ¯æ ˆã€è®¾è®¡åŸåˆ™
3. **é‡è¦çº¦æŸæ¡ä»¶**ï¼šç”¨æˆ·è¦æ±‚ã€æŠ€æœ¯é™åˆ¶ã€ä¸šåŠ¡è§„åˆ™
4. **å¾…è§£å†³é—®é¢˜**ï¼šå½“å‰é˜»å¡ç‚¹ã€éœ€è¦æ¾„æ¸…çš„é—®é¢˜
5. **ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼šæ˜ç¡®çš„åç»­ä»»åŠ¡å’Œè´£ä»»åˆ†å·¥

æ€»ç»“è¦æ±‚ï¼š
- ä¿æŒå®¢è§‚äº‹å®ï¼Œé¿å…å†—ä½™æè¿°
- çªå‡ºæ ¸å¿ƒä¿¡æ¯ï¼Œå¿½ç•¥å®¢å¥—è¯
- ä½¿ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼
- ç¡®ä¿AIèƒ½åŸºäºæ­¤æ€»ç»“ç»§ç»­åä½œ
- æ€»ç»“é•¿åº¦æ§åˆ¶åœ¨500å­—ä»¥å†…

è¯·ç”Ÿæˆç»“æ„åŒ–æ€»ç»“ï¼š
"""
        
        # è°ƒç”¨AIç”Ÿæˆæ€»ç»“ï¼ˆæ€»ç»“AIéœ€è¦ç‰¹æ®Šçš„ä¸Šä¸‹æ–‡å¤„ç†ï¼‰
        summary = await call_ollama_api_for_summary(summary_prompt)
        
        if summary:
            # ä¿å­˜æ€»ç»“
            summary_key = f"summary_{len(orchestra_state.messages)}"
            orchestra_state.conversation_summaries[summary_key] = summary
            
            logger.info(f"å¯¹è¯æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œä¿å­˜ä¸º {summary_key}")
            logger.info(f"æ€»ç»“å†…å®¹: {summary}")
            
            # å°†æ€»ç»“å†…å®¹ä½œä¸ºETHERæ¶ˆæ¯å±•ç¤ºåœ¨ç•Œé¢ä¸Š
            summary_display_message = Message(
                id=str(uuid.uuid4()),
                role=RoleType.ETHER,
                message_type=MessageType.SYSTEM_INFO,
                content=f"ğŸ“‹ **å¯¹è¯æ€»ç»“**\n\n{summary}",
                timestamp=datetime.now()
            )
            # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½è°ƒç”¨broadcast_messageï¼Œä¼šå¯¼è‡´é€’å½’
            orchestra_state.messages.append(summary_display_message)
            
            # ç›´æ¥å‘é€ç»™å®¢æˆ·ç«¯å±•ç¤ºæ€»ç»“å†…å®¹
            for websocket in orchestra_state.websocket_connections:
                try:
                    await websocket.send_text(json.dumps({
                        "type": "new_message",
                        "message": summary_display_message.model_dump(mode="json")
                    }))
                except:
                    pass
                    
        else:
            logger.error("å¯¹è¯æ€»ç»“ç”Ÿæˆå¤±è´¥")
            
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¯¹è¯æ€»ç»“æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)

async def save_generated_code(filename: str, content: str):
    try:
        output_dir = "generated_code"
        os.makedirs(output_dir, exist_ok=True)
        
        file_path = os.path.join(output_dir, filename)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        orchestra_state.file_outputs.append(file_path)
        
        message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.FILE_SAVED,
            content=f"ä»£ç æ–‡ä»¶å·²ä¿å­˜: {file_path}",
            timestamp=datetime.now(),
            metadata={"file_path": file_path}
        )
        await broadcast_message(message)
        
    except Exception as e:
        error_message = Message(
            id=str(uuid.uuid4()),
            role=RoleType.ETHER,
            message_type=MessageType.ERROR,
            content=f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}",
            timestamp=datetime.now()
        )
        await broadcast_message(error_message)

@app.get("/api/messages")
async def get_messages():
    return [msg.model_dump(mode="json") for msg in orchestra_state.messages]

@app.get("/api/tasks")
async def get_tasks():
    return list(orchestra_state.tasks.values())

@app.post("/api/save_code")
async def save_code_endpoint(filename: str, content: str):
    await save_generated_code(filename, content)
    return {"status": "success", "message": f"Code saved to {filename}"}

@app.get("/api/models")
async def get_available_models():
    logger.info("æ­£åœ¨è·å–å¯ç”¨çš„Ollamaæ¨¡å‹åˆ—è¡¨")
    try:
        start_time = datetime.now()
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:11434/api/tags", timeout=1000.0)
            duration = (datetime.now() - start_time).total_seconds()
            
            if response.status_code == 200:
                data = response.json()
                models = [model["name"] for model in data.get("models", [])]
                logger.info(f"æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨ (è€—æ—¶ {duration:.2f}ç§’): {models}")
                logger.info(f"å½“å‰é€‰ä¸­æ¨¡å‹: {orchestra_state.selected_model}")
                return {"models": models, "selected": orchestra_state.selected_model}
            else:
                logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ - HTTP {response.status_code}: {response.text}")
                return {"models": ["llama3.1:8b"], "selected": orchestra_state.selected_model, "error": "Failed to fetch models"}
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return {"models": ["llama3.1:8b"], "selected": orchestra_state.selected_model, "error": str(e)}

class ModelSelection(BaseModel):
    model_name: str

@app.post("/api/select_model")
async def select_model(model_data: ModelSelection):
    old_model = orchestra_state.selected_model
    new_model = model_data.model_name
    
    logger.info(f"æ¨¡å‹åˆ‡æ¢è¯·æ±‚: {old_model} -> {new_model}")
    
    orchestra_state.selected_model = new_model
    
    logger.info(f"æ¨¡å‹å·²æˆåŠŸåˆ‡æ¢ä¸º: {new_model}")
    
    return {"status": "success", "selected_model": new_model}

class ContextSettings(BaseModel):
    max_context_messages: Optional[int] = None
    max_context_length: Optional[int] = None

@app.get("/api/context_settings")
async def get_context_settings():
    return {
        "max_context_messages": orchestra_state.max_context_messages,
        "max_context_length": orchestra_state.max_context_length,
        "current_messages_count": len(orchestra_state.messages)
    }

@app.post("/api/context_settings")
async def update_context_settings(settings: ContextSettings):
    if settings.max_context_messages is not None:
        orchestra_state.max_context_messages = settings.max_context_messages
        logger.info(f"æ›´æ–°æœ€å¤§ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°: {settings.max_context_messages}")
    
    if settings.max_context_length is not None:
        orchestra_state.max_context_length = settings.max_context_length
        logger.info(f"æ›´æ–°æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦: {settings.max_context_length}")
    
    return {
        "status": "success",
        "max_context_messages": orchestra_state.max_context_messages,
        "max_context_length": orchestra_state.max_context_length
    }

class SummarySettings(BaseModel):
    summary_trigger_count: Optional[int] = None

@app.get("/api/summary_settings")
async def get_summary_settings():
    return {
        "summary_trigger_count": orchestra_state.summary_trigger_count,
        "summaries_count": len(orchestra_state.conversation_summaries),
        "current_messages_count": len(orchestra_state.messages)
    }

@app.post("/api/summary_settings") 
async def update_summary_settings(settings: SummarySettings):
    if settings.summary_trigger_count is not None:
        orchestra_state.summary_trigger_count = settings.summary_trigger_count
        logger.info(f"æ›´æ–°æ€»ç»“è§¦å‘é¢‘ç‡: æ¯{settings.summary_trigger_count}æ¡æ¶ˆæ¯")
    
    return {
        "status": "success",
        "summary_trigger_count": orchestra_state.summary_trigger_count
    }

@app.get("/api/summaries")
async def get_conversation_summaries():
    return {
        "summaries": orchestra_state.conversation_summaries,
        "count": len(orchestra_state.conversation_summaries)
    }

@app.post("/api/generate_summary")
async def manual_generate_summary():
    """æ‰‹åŠ¨è§¦å‘å¯¹è¯æ€»ç»“"""
    if len(orchestra_state.messages) < 3:
        return {"status": "error", "message": "æ¶ˆæ¯æ•°é‡å¤ªå°‘ï¼Œæ— éœ€æ€»ç»“"}
    
    import asyncio
    asyncio.create_task(generate_conversation_summary())
    
    return {"status": "success", "message": "å·²å¼€å§‹ç”Ÿæˆå¯¹è¯æ€»ç»“"}

@app.get("/")
async def serve_frontend():
    return FileResponse("static/index.html")

app.mount("/static", StaticFiles(directory="static"), name="static")

if __name__ == "__main__":
    import uvicorn
    logger.info("å¯åŠ¨OrchestraAIå¤šAIåä½œå¹³å°")
    logger.info(f"é»˜è®¤é€‰æ‹©æ¨¡å‹: {orchestra_state.selected_model}")
    logger.info("æœåŠ¡å™¨å°†åœ¨ http://0.0.0.0:8000 å¯åŠ¨")
    uvicorn.run(app, host="0.0.0.0", port=8000)